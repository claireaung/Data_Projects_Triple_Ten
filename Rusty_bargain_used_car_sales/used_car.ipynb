{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You have access to historical data: technical specifications, trim versions, and prices. You need to build the model to determine the value. \n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "import timeit\n",
    "from functools import lru_cache\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "import random\n",
    "random_state=42\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values\n",
    "def missing_values(df):\n",
    "    df_nulls = pd.concat([df.dtypes, df.isna().sum(), df.isna().sum()/len(df)], axis=1)\n",
    "    df_nulls.columns = [\"type\", \"count\", \"missing_ratio\"]\n",
    "    df_nulls = df_nulls[df_nulls[\"count\"]>0]\n",
    "    df_nulls.sort_values(by='missing_ratio', ascending=False)\n",
    "    return df_nulls\n",
    "\n",
    "def outlier(data):\n",
    "    data_mean, data_std = np.mean(data), np.std(data)\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    outliers = [x for x in data if x < lower or x > upper]\n",
    "    outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "    return len(outliers)\n",
    "\n",
    "def plot_roc(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        if not ax: fig, ax = plt.sublots(1,1)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "        ax.plot([0,1], [0,1], 'r--')\n",
    "        ax.plot(fpr, tpr, lw=2, label=label)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_title(\n",
    "            'ROC curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                    y_test, preds, pos_label=1):.2} | \"\"\"\n",
    "            f'AUC: {auc(fpr, tpr):.2}')\n",
    "        ax.set_xlabel('False Positive Rate (FPR)')\n",
    "        ax.set_ylabel('True Positive Rate (TPR)')\n",
    "        ax.annotate(f'AUC: {auc(fpr, tpr):.2}', xy=(.43, .025))\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax\n",
    "\n",
    "def plot_pr(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "        if not ax: fig, ax = plt.subplots()\n",
    "        ax.plot([0,1], [1,0], 'r--')\n",
    "        ax.plot(recall, precision, lw=2, label=label)\n",
    "        ax.legend()\n",
    "        ax.set_title(\n",
    "            'Precision-recall curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(recall, precision):.2}'\n",
    "        )\n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.set_xlim(-0.05, 1.05)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax\n",
    "    \n",
    "def des_full(df, target_name=\"\"):\n",
    "    data_describe = df.describe().T\n",
    "    df_numeric = df._get_numeric_data()\n",
    "    if target_name in df.columns:\n",
    "        corr_with_target=df_numeric.drop(target_name, axis=1).apply(lambda x: x.corr(df_numeric[target_name]))\n",
    "        data_describe['corr_with_target']=corr_with_target\n",
    "    dtype_df = df_numeric.dtypes\n",
    "    data_describe['dtypes'] = dtype_df\n",
    "    data_null = df_numeric.isnull().sum()/len(df) * 100\n",
    "    data_describe['Missing %'] = data_null\n",
    "    Cardinality = df_numeric.apply(pd.Series.nunique)\n",
    "    data_describe['Cardinality'] = Cardinality\n",
    "    df_skew = df_numeric.skew(axis=0, skipna=True)\n",
    "    data_describe['Skew'] = df_skew\n",
    "    data_describe['outliers %']=[outlier(df_numeric[col])/len(df) * 100 for col in df_numeric.columns]\n",
    "    data_describe['kurtosis']=df_numeric.kurtosis()\n",
    "    return data_describe\n",
    "\n",
    "def show_importances(df, features, target):\n",
    "  X, y = df[features].values,df[target].values\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "  rfc = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "  y_pred = rfc.predict(X_test)\n",
    "  df_importances = pd.DataFrame(((zip(features, rfc.feature_importances_)))).rename(columns={0:\"feature\",1:\"coeff\"}).sort_values(by=\"coeff\", ascending = False )\n",
    "  sns.barplot(data=feature_importances, x=df_importances[\"coeff\"], y=df_importances[\"feature\"])\n",
    "  return df_importances\n",
    "\n",
    "def display_classification_report(y_true, y_pred):\n",
    "    display(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='Price'\n",
    "features = list(set(df.columns)-set(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/03/2016 11:52</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>07/04/2016 03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/03/2016 10:58</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>07/04/2016 01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/03/2016 12:52</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>05/04/2016 12:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/03/2016 16:54</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>17/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>17/03/2016 17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2016 17:25</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>31/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>06/04/2016 10:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  24/03/2016 11:52    480         NaN              1993  manual      0   \n",
       "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
       "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
       "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
       "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf   150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN   125000                  5  gasoline        audi         yes   \n",
       "2  grand   125000                  8  gasoline        jeep         NaN   \n",
       "3   golf   150000                  6    petrol  volkswagen          no   \n",
       "4  fabia    90000                  7  gasoline       skoda          no   \n",
       "\n",
       "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
       "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
       "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
       "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
       "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
       "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to datetime\n",
    "df['DataCrawled'] = pd.to_datetime(df['DateCrawled'])\n",
    "df['DataCreated'] = pd.to_datetime(df['DateCreated'])\n",
    "df['LastSeen'] = pd.to_datetime(df['LastSeen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's impute\n",
    "df['NotRepaired'] = df['NotRepaired'].fillna('yes')\n",
    "df['NotReparied'] = (df['NotRepaired'] == 'yes').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gearbox'] = (df['Gearbox'] == 'auto').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateCrawled              0\n",
       "Price                    0\n",
       "VehicleType          37490\n",
       "RegistrationYear         0\n",
       "Gearbox                  0\n",
       "Power                    0\n",
       "Model                19705\n",
       "Mileage                  0\n",
       "RegistrationMonth        0\n",
       "FuelType             32895\n",
       "Brand                    0\n",
       "NotRepaired              0\n",
       "DateCreated              0\n",
       "NumberOfPictures         0\n",
       "PostalCode               0\n",
       "LastSeen                 0\n",
       "DataCrawled              0\n",
       "DataCreated              0\n",
       "NotReparied              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_value(in_df, features, target):\n",
    "    encoders = dict()\n",
    "    df = in_df.copy()\n",
    "    for col in df[features].select_dtypes('object').columns:\n",
    "        df.loc[df[col].isna(), col] = 'None'\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        encoders[col] = le\n",
    "    for col in df[features].select_dtypes('datetime64').columns:\n",
    "        df[f\"{col}_hour\"] = df[col].dt.hour\n",
    "        df[f\"{col}_month\"] = df[col].dt.month\n",
    "        df[f\"{col}_day\"] = df[col].dt.day\n",
    "        del df[col]\n",
    "    features=list(set(df.columns)-set([target]))\n",
    "    train_df = df[~df[target].isna()]\n",
    "    test_df = df[df[target].isna()]\n",
    "    let = LabelEncoder()\n",
    "    y_train = let.fit_transform(train_df[target])\n",
    "    y_train = train_df[target].values\n",
    "    X_train, X_test = train_df[features].values, test_df[features].values\n",
    "    if len(X_test) == 0:\n",
    "        return in_df\n",
    "    model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    df.loc[df[target].isna(), target] = y_pred\n",
    "    in_df[target] = df[target]\n",
    "    return in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"FuelType\", \"VehicleType\", \"Model\"]:\n",
    "    df=impute_value(df, features=list(set(df.columns)-set([col])-set([target])), target=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_full(df, target_name=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, transform_data=True, apply_encoding=True):\n",
    "    in_df = df.copy()\n",
    "    target = \"Price\"\n",
    "    features = list(set(in_df.columns) - set([target]))\n",
    "    \n",
    "    # Transform datetime columns\n",
    "    if transform_data:\n",
    "        for col in in_df[features].select_dtypes(include=['datetime64[ns]']).columns:\n",
    "            in_df[f\"{col}_hour\"] = in_df[col].dt.hour\n",
    "            in_df[f\"{col}_month\"] = in_df[col].dt.month\n",
    "            in_df[f\"{col}_day\"] = in_df[col].dt.day\n",
    "            del in_df[col]  # Remove original datetime column\n",
    "    \n",
    "    # Update feature list after transformation\n",
    "    features = list(set(in_df.columns) - set([target]))\n",
    "\n",
    "    # Remove constant features\n",
    "    constant_features = [col for col in features if in_df[col].nunique() <= 1]\n",
    "    in_df.drop(columns=constant_features, inplace=True)\n",
    "    features = list(set(in_df.columns) - set([target]))\n",
    "\n",
    "    encoders = dict()\n",
    "    if apply_encoding:\n",
    "        for col in in_df[features].select_dtypes('object').columns:\n",
    "            lbl = LabelEncoder()\n",
    "            in_df[col] = lbl.fit_transform(in_df[col].astype(str).fillna('missing_value'))\n",
    "            encoders[col] = lbl\n",
    "\n",
    "    # Ensure all categorical features are converted to numeric\n",
    "    cat_features = list(in_df[features].select_dtypes('object').columns)\n",
    "    in_df[cat_features] = in_df[cat_features].astype(str).fillna('NaN')\n",
    "    in_df[cat_features] = in_df[cat_features].apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    return in_df[features].values, in_df[target].values, features, target, encoders, cat_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_func = lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False)\n",
    "rmsle = make_scorer(rmse_func, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_met = {\"models\": [\"catboost\", \"xgboost\", \"LGBM\"], \"rmse_init\": [0.0]*3, \"fit_time\": [0.0]*3, \"predict_time\": [0.0]*3}\n",
    "m_idx = {\"catboost\": 0, \"xgboost\": 1, \"LGBM\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"CatBoost can natively handle categorical data, which is a key feature of the algorithm. For other models, we'll use a simple LabelEncoder for convenience. However, in practice, it's important to carefully consider how categorical data is encoded, especially when the data's order is significant, such as with prices.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features, target, _, cat_features = get_data(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state)\n",
    "\n",
    "train_ds = Pool(data=X_train, label=y_train, cat_features=cat_features, feature_names=features)\n",
    "test_ds = Pool(data=X_test, label=y_test, cat_features=cat_features, feature_names=features)\n",
    "full_ds = Pool(data=X, label=y, cat_features=cat_features, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost RMSE: 2015.1266237324533\n",
      "CatBoost Fit time: 2.477708101272583 seconds, Predict time: 0.005808115005493164 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train initial CatBoost model\n",
    "model = CatBoostRegressor(iterations=20, task_type=\"CPU\", random_seed=random_state, loss_function='RMSE')\n",
    "\n",
    "start_fit = time.time()\n",
    "model.fit(train_ds, verbose=0)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_predict = time.time()\n",
    "y_pred = model.predict(test_ds)\n",
    "predict_time = time.time() - start_predict\n",
    "\n",
    "rmse = rmse_func(y_test, y_pred)\n",
    "print(f\"CatBoost RMSE: {rmse}\")\n",
    "print(f\"CatBoost Fit time: {fit_time} seconds, Predict time: {predict_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_met[\"rmse_init\"][m_idx[\"catboost\"]] = rmse\n",
    "log_met[\"fit_time\"][m_idx[\"catboost\"]] = fit_time\n",
    "log_met[\"predict_time\"][m_idx[\"catboost\"]] = predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6164.9575944\ttest: 6116.4025696\tbest: 6116.4025696 (0)\ttotal: 113ms\tremaining: 2.15s\n",
      "1:\tlearn: 6016.7853636\ttest: 5968.0901319\tbest: 5968.0901319 (1)\ttotal: 209ms\tremaining: 1.88s\n",
      "2:\tlearn: 5873.5708465\ttest: 5824.2542823\tbest: 5824.2542823 (2)\ttotal: 305ms\tremaining: 1.73s\n",
      "3:\tlearn: 5736.1446797\ttest: 5686.8466099\tbest: 5686.8466099 (3)\ttotal: 410ms\tremaining: 1.64s\n",
      "4:\tlearn: 5603.5312444\ttest: 5554.9544509\tbest: 5554.9544509 (4)\ttotal: 513ms\tremaining: 1.54s\n",
      "5:\tlearn: 5474.5716537\ttest: 5425.8219143\tbest: 5425.8219143 (5)\ttotal: 607ms\tremaining: 1.42s\n",
      "6:\tlearn: 5350.4911938\ttest: 5301.6301622\tbest: 5301.6301622 (6)\ttotal: 705ms\tremaining: 1.31s\n",
      "7:\tlearn: 5230.0738046\ttest: 5181.0107126\tbest: 5181.0107126 (7)\ttotal: 802ms\tremaining: 1.2s\n",
      "8:\tlearn: 5114.7713375\ttest: 5065.5719369\tbest: 5065.5719369 (8)\ttotal: 894ms\tremaining: 1.09s\n",
      "9:\tlearn: 5003.8433654\ttest: 4954.5650339\tbest: 4954.5650339 (9)\ttotal: 993ms\tremaining: 993ms\n",
      "10:\tlearn: 4897.2582568\ttest: 4847.9213455\tbest: 4847.9213455 (10)\ttotal: 1.1s\tremaining: 899ms\n",
      "11:\tlearn: 4794.8354166\ttest: 4745.2905123\tbest: 4745.2905123 (11)\ttotal: 1.21s\tremaining: 803ms\n",
      "12:\tlearn: 4694.7561497\ttest: 4645.0261852\tbest: 4645.0261852 (12)\ttotal: 1.3s\tremaining: 703ms\n",
      "13:\tlearn: 4598.1088256\ttest: 4549.3379491\tbest: 4549.3379491 (13)\ttotal: 1.4s\tremaining: 602ms\n",
      "14:\tlearn: 4505.2729594\ttest: 4456.4184026\tbest: 4456.4184026 (14)\ttotal: 1.52s\tremaining: 506ms\n",
      "15:\tlearn: 4416.0110415\ttest: 4367.1665017\tbest: 4367.1665017 (15)\ttotal: 1.62s\tremaining: 405ms\n",
      "16:\tlearn: 4329.0900503\ttest: 4280.5910268\tbest: 4280.5910268 (16)\ttotal: 1.72s\tremaining: 303ms\n",
      "17:\tlearn: 4245.7703217\ttest: 4197.0899620\tbest: 4197.0899620 (17)\ttotal: 1.82s\tremaining: 202ms\n",
      "18:\tlearn: 4166.1173181\ttest: 4117.4196018\tbest: 4117.4196018 (18)\ttotal: 1.92s\tremaining: 101ms\n",
      "19:\tlearn: 4089.8228583\ttest: 4041.3523881\tbest: 4041.3523881 (19)\ttotal: 2.02s\tremaining: 0us\n",
      "\n",
      "bestTest = 4041.352388\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 5815.0082634\ttest: 5765.0373329\tbest: 5765.0373329 (0)\ttotal: 113ms\tremaining: 2.14s\n",
      "1:\tlearn: 5363.2065739\ttest: 5312.9670299\tbest: 5312.9670299 (1)\ttotal: 211ms\tremaining: 1.9s\n",
      "2:\tlearn: 4966.2702165\ttest: 4917.1004887\tbest: 4917.1004887 (2)\ttotal: 308ms\tremaining: 1.74s\n",
      "3:\tlearn: 4608.5928150\ttest: 4559.3092479\tbest: 4559.3092479 (3)\ttotal: 408ms\tremaining: 1.63s\n",
      "4:\tlearn: 4300.3709145\ttest: 4253.6531655\tbest: 4253.6531655 (4)\ttotal: 510ms\tremaining: 1.53s\n",
      "5:\tlearn: 4030.2012365\ttest: 3984.4012251\tbest: 3984.4012251 (5)\ttotal: 617ms\tremaining: 1.44s\n",
      "6:\tlearn: 3792.8331085\ttest: 3748.2832771\tbest: 3748.2832771 (6)\ttotal: 709ms\tremaining: 1.32s\n",
      "7:\tlearn: 3579.4109151\ttest: 3534.5773059\tbest: 3534.5773059 (7)\ttotal: 804ms\tremaining: 1.21s\n",
      "8:\tlearn: 3397.3788212\ttest: 3353.4557917\tbest: 3353.4557917 (8)\ttotal: 894ms\tremaining: 1.09s\n",
      "9:\tlearn: 3239.0577290\ttest: 3196.6992528\tbest: 3196.6992528 (9)\ttotal: 993ms\tremaining: 993ms\n",
      "10:\tlearn: 3104.9272867\ttest: 3064.0884938\tbest: 3064.0884938 (10)\ttotal: 1.1s\tremaining: 899ms\n",
      "11:\tlearn: 2984.0507009\ttest: 2943.7358583\tbest: 2943.7358583 (11)\ttotal: 1.19s\tremaining: 793ms\n",
      "12:\tlearn: 2880.8136214\ttest: 2841.1507357\tbest: 2841.1507357 (12)\ttotal: 1.26s\tremaining: 681ms\n",
      "13:\tlearn: 2791.9825311\ttest: 2754.8681336\tbest: 2754.8681336 (13)\ttotal: 1.37s\tremaining: 587ms\n",
      "14:\tlearn: 2714.0557918\ttest: 2678.8049236\tbest: 2678.8049236 (14)\ttotal: 1.46s\tremaining: 486ms\n",
      "15:\tlearn: 2645.6619692\ttest: 2611.8608527\tbest: 2611.8608527 (15)\ttotal: 1.55s\tremaining: 387ms\n",
      "16:\tlearn: 2588.0345124\ttest: 2555.7373257\tbest: 2555.7373257 (16)\ttotal: 1.64s\tremaining: 290ms\n",
      "17:\tlearn: 2535.4548055\ttest: 2504.1207168\tbest: 2504.1207168 (17)\ttotal: 1.73s\tremaining: 192ms\n",
      "18:\tlearn: 2492.4505379\ttest: 2462.8556809\tbest: 2462.8556809 (18)\ttotal: 1.83s\tremaining: 96.5ms\n",
      "19:\tlearn: 2453.5428152\ttest: 2426.1782160\tbest: 2426.1782160 (19)\ttotal: 1.92s\tremaining: 0us\n",
      "\n",
      "bestTest = 2426.178216\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 6165.0331896\ttest: 6116.4787813\tbest: 6116.4787813 (0)\ttotal: 115ms\tremaining: 2.19s\n",
      "1:\tlearn: 6016.9115635\ttest: 5968.2179335\tbest: 5968.2179335 (1)\ttotal: 212ms\tremaining: 1.91s\n",
      "2:\tlearn: 5874.0849013\ttest: 5825.1475940\tbest: 5825.1475940 (2)\ttotal: 313ms\tremaining: 1.78s\n",
      "3:\tlearn: 5736.5397566\ttest: 5687.6220174\tbest: 5687.6220174 (3)\ttotal: 417ms\tremaining: 1.67s\n",
      "4:\tlearn: 5603.1283314\ttest: 5554.5005935\tbest: 5554.5005935 (4)\ttotal: 526ms\tremaining: 1.58s\n",
      "5:\tlearn: 5474.2242356\ttest: 5425.6087578\tbest: 5425.6087578 (5)\ttotal: 618ms\tremaining: 1.44s\n",
      "6:\tlearn: 5350.9416111\ttest: 5302.2925812\tbest: 5302.2925812 (6)\ttotal: 726ms\tremaining: 1.35s\n",
      "7:\tlearn: 5230.4446436\ttest: 5181.5967855\tbest: 5181.5967855 (7)\ttotal: 822ms\tremaining: 1.23s\n",
      "8:\tlearn: 5115.0043329\ttest: 5066.0243092\tbest: 5066.0243092 (8)\ttotal: 915ms\tremaining: 1.12s\n",
      "9:\tlearn: 5004.3039453\ttest: 4955.2516231\tbest: 4955.2516231 (9)\ttotal: 1.01s\tremaining: 1.01s\n",
      "10:\tlearn: 4897.9442676\ttest: 4848.8346290\tbest: 4848.8346290 (10)\ttotal: 1.12s\tremaining: 913ms\n",
      "11:\tlearn: 4795.4263149\ttest: 4746.1099361\tbest: 4746.1099361 (11)\ttotal: 1.22s\tremaining: 816ms\n",
      "12:\tlearn: 4695.2282710\ttest: 4645.7373149\tbest: 4645.7373149 (12)\ttotal: 1.32s\tremaining: 713ms\n",
      "13:\tlearn: 4598.9061985\ttest: 4550.2796633\tbest: 4550.2796633 (13)\ttotal: 1.42s\tremaining: 608ms\n",
      "14:\tlearn: 4506.2463399\ttest: 4457.4410004\tbest: 4457.4410004 (14)\ttotal: 1.53s\tremaining: 510ms\n",
      "15:\tlearn: 4417.1763413\ttest: 4368.3848167\tbest: 4368.3848167 (15)\ttotal: 1.63s\tremaining: 408ms\n",
      "16:\tlearn: 4330.2579730\ttest: 4281.8116226\tbest: 4281.8116226 (16)\ttotal: 1.73s\tremaining: 305ms\n",
      "17:\tlearn: 4246.6038274\ttest: 4198.0346281\tbest: 4198.0346281 (17)\ttotal: 1.83s\tremaining: 204ms\n",
      "18:\tlearn: 4167.0123574\ttest: 4118.4297357\tbest: 4118.4297357 (18)\ttotal: 1.94s\tremaining: 102ms\n",
      "19:\tlearn: 4090.7175528\ttest: 4042.2510555\tbest: 4042.2510555 (19)\ttotal: 2.03s\tremaining: 0us\n",
      "\n",
      "bestTest = 4042.251056\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 5815.2561674\ttest: 5765.2873344\tbest: 5765.2873344 (0)\ttotal: 116ms\tremaining: 2.21s\n",
      "1:\tlearn: 5363.5875305\ttest: 5313.3522561\tbest: 5313.3522561 (1)\ttotal: 211ms\tremaining: 1.9s\n",
      "2:\tlearn: 4966.7783442\ttest: 4917.6124099\tbest: 4917.6124099 (2)\ttotal: 308ms\tremaining: 1.75s\n",
      "3:\tlearn: 4609.1436337\ttest: 4559.8629973\tbest: 4559.8629973 (3)\ttotal: 413ms\tremaining: 1.65s\n",
      "4:\tlearn: 4300.9840108\ttest: 4254.2683340\tbest: 4254.2683340 (4)\ttotal: 518ms\tremaining: 1.55s\n",
      "5:\tlearn: 4030.8171405\ttest: 3985.0175527\tbest: 3985.0175527 (5)\ttotal: 620ms\tremaining: 1.45s\n",
      "6:\tlearn: 3793.4344898\ttest: 3748.8787365\tbest: 3748.8787365 (6)\ttotal: 719ms\tremaining: 1.33s\n",
      "7:\tlearn: 3580.0079544\ttest: 3535.1679354\tbest: 3535.1679354 (7)\ttotal: 813ms\tremaining: 1.22s\n",
      "8:\tlearn: 3397.9871674\ttest: 3354.0481677\tbest: 3354.0481677 (8)\ttotal: 912ms\tremaining: 1.11s\n",
      "9:\tlearn: 3239.6535441\ttest: 3197.2732832\tbest: 3197.2732832 (9)\ttotal: 1.02s\tremaining: 1.02s\n",
      "10:\tlearn: 3105.4972074\ttest: 3064.6317131\tbest: 3064.6317131 (10)\ttotal: 1.13s\tremaining: 924ms\n",
      "11:\tlearn: 2984.5927553\ttest: 2944.2491363\tbest: 2944.2491363 (11)\ttotal: 1.22s\tremaining: 815ms\n",
      "12:\tlearn: 2881.3539030\ttest: 2841.6545168\tbest: 2841.6545168 (12)\ttotal: 1.3s\tremaining: 702ms\n",
      "13:\tlearn: 2792.5072951\ttest: 2755.3511778\tbest: 2755.3511778 (13)\ttotal: 1.41s\tremaining: 605ms\n",
      "14:\tlearn: 2714.5340023\ttest: 2679.2388698\tbest: 2679.2388698 (14)\ttotal: 1.5s\tremaining: 499ms\n",
      "15:\tlearn: 2646.1595487\ttest: 2612.3136563\tbest: 2612.3136563 (15)\ttotal: 1.59s\tremaining: 397ms\n",
      "16:\tlearn: 2588.5116693\ttest: 2556.1681146\tbest: 2556.1681146 (16)\ttotal: 1.68s\tremaining: 296ms\n",
      "17:\tlearn: 2535.9351143\ttest: 2504.5486590\tbest: 2504.5486590 (17)\ttotal: 1.77s\tremaining: 196ms\n",
      "18:\tlearn: 2492.8207686\ttest: 2462.8874044\tbest: 2462.8874044 (18)\ttotal: 1.86s\tremaining: 98.2ms\n",
      "19:\tlearn: 2453.7445034\ttest: 2426.0468880\tbest: 2426.0468880 (19)\ttotal: 1.95s\tremaining: 0us\n",
      "\n",
      "bestTest = 2426.046888\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 6165.1086411\ttest: 6116.5548560\tbest: 6116.5548560 (0)\ttotal: 111ms\tremaining: 2.11s\n",
      "1:\tlearn: 6017.0373395\ttest: 5968.3452661\tbest: 5968.3452661 (1)\ttotal: 205ms\tremaining: 1.85s\n",
      "2:\tlearn: 5874.2698047\ttest: 5825.3342764\tbest: 5825.3342764 (2)\ttotal: 309ms\tremaining: 1.75s\n",
      "3:\tlearn: 5736.7753668\ttest: 5687.8610243\tbest: 5687.8610243 (3)\ttotal: 411ms\tremaining: 1.64s\n",
      "4:\tlearn: 5603.4067327\ttest: 5554.7824415\tbest: 5554.7824415 (4)\ttotal: 521ms\tremaining: 1.56s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5:\tlearn: 5474.5254350\ttest: 5425.9133760\tbest: 5425.9133760 (5)\ttotal: 612ms\tremaining: 1.43s\n",
      "6:\tlearn: 5351.2828726\ttest: 5302.6375900\tbest: 5302.6375900 (6)\ttotal: 721ms\tremaining: 1.34s\n",
      "7:\tlearn: 5230.8024139\ttest: 5181.9574752\tbest: 5181.9574752 (7)\ttotal: 819ms\tremaining: 1.23s\n",
      "8:\tlearn: 5115.4001324\ttest: 5066.4228751\tbest: 5066.4228751 (8)\ttotal: 912ms\tremaining: 1.11s\n",
      "9:\tlearn: 5004.7480489\ttest: 4955.7006056\tbest: 4955.7006056 (9)\ttotal: 1.01s\tremaining: 1.01s\n",
      "10:\tlearn: 4898.4061457\ttest: 4849.3015470\tbest: 4849.3015470 (10)\ttotal: 1.11s\tremaining: 912ms\n",
      "11:\tlearn: 4795.8896012\ttest: 4746.5778067\tbest: 4746.5778067 (11)\ttotal: 1.22s\tremaining: 814ms\n",
      "12:\tlearn: 4695.7072543\ttest: 4646.2202523\tbest: 4646.2202523 (12)\ttotal: 1.32s\tremaining: 712ms\n",
      "13:\tlearn: 4599.4169144\ttest: 4550.7926462\tbest: 4550.7926462 (13)\ttotal: 1.42s\tremaining: 607ms\n",
      "14:\tlearn: 4506.7580822\ttest: 4457.9546983\tbest: 4457.9546983 (14)\ttotal: 1.53s\tremaining: 509ms\n",
      "15:\tlearn: 4417.7113732\ttest: 4368.9212323\tbest: 4368.9212323 (15)\ttotal: 1.62s\tremaining: 406ms\n",
      "16:\tlearn: 4330.8078455\ttest: 4282.3629067\tbest: 4282.3629067 (16)\ttotal: 1.72s\tremaining: 303ms\n",
      "17:\tlearn: 4247.1549568\ttest: 4198.5865998\tbest: 4198.5865998 (17)\ttotal: 1.83s\tremaining: 203ms\n",
      "18:\tlearn: 4167.5763870\ttest: 4118.9949147\tbest: 4118.9949147 (18)\ttotal: 1.93s\tremaining: 101ms\n",
      "19:\tlearn: 4091.2857425\ttest: 4042.8198436\tbest: 4042.8198436 (19)\ttotal: 2.02s\tremaining: 0us\n",
      "\n",
      "bestTest = 4042.819844\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 5815.5036116\ttest: 5765.5368962\tbest: 5765.5368962 (0)\ttotal: 118ms\tremaining: 2.24s\n",
      "1:\tlearn: 5363.9672866\ttest: 5313.7361779\tbest: 5313.7361779 (1)\ttotal: 212ms\tremaining: 1.91s\n",
      "2:\tlearn: 4967.2848902\ttest: 4918.1226846\tbest: 4918.1226846 (2)\ttotal: 308ms\tremaining: 1.75s\n",
      "3:\tlearn: 4609.6929206\ttest: 4560.4151633\tbest: 4560.4151633 (3)\ttotal: 413ms\tremaining: 1.65s\n",
      "4:\tlearn: 4301.5955737\ttest: 4254.8819289\tbest: 4254.8819289 (4)\ttotal: 518ms\tremaining: 1.55s\n",
      "5:\tlearn: 4031.4318326\ttest: 3985.6326624\tbest: 3985.6326624 (5)\ttotal: 622ms\tremaining: 1.45s\n",
      "6:\tlearn: 3794.0346565\ttest: 3749.4730711\tbest: 3749.4730711 (6)\ttotal: 712ms\tremaining: 1.32s\n",
      "7:\tlearn: 3580.6039620\ttest: 3535.7576614\tbest: 3535.7576614 (7)\ttotal: 806ms\tremaining: 1.21s\n",
      "8:\tlearn: 3398.5942912\ttest: 3354.6398134\tbest: 3354.6398134 (8)\ttotal: 902ms\tremaining: 1.1s\n",
      "9:\tlearn: 3240.2480114\ttest: 3197.8465454\tbest: 3197.8465454 (9)\ttotal: 1000ms\tremaining: 1000ms\n",
      "10:\tlearn: 3106.0658753\ttest: 3065.1743205\tbest: 3065.1743205 (10)\ttotal: 1.1s\tremaining: 901ms\n",
      "11:\tlearn: 2985.1337464\ttest: 2944.7620345\tbest: 2944.7620345 (11)\ttotal: 1.19s\tremaining: 796ms\n",
      "12:\tlearn: 2881.8924433\ttest: 2842.1581271\tbest: 2842.1581271 (12)\ttotal: 1.28s\tremaining: 687ms\n",
      "13:\tlearn: 2793.0302675\ttest: 2755.8342977\tbest: 2755.8342977 (13)\ttotal: 1.38s\tremaining: 592ms\n",
      "14:\tlearn: 2715.0106325\ttest: 2679.6731900\tbest: 2679.6731900 (14)\ttotal: 1.47s\tremaining: 491ms\n",
      "15:\tlearn: 2646.6542210\ttest: 2612.7663931\tbest: 2612.7663931 (15)\ttotal: 1.56s\tremaining: 391ms\n",
      "16:\tlearn: 2588.9854288\ttest: 2556.5981394\tbest: 2556.5981394 (16)\ttotal: 1.65s\tremaining: 292ms\n",
      "17:\tlearn: 2538.4617571\ttest: 2507.2614807\tbest: 2507.2614807 (17)\ttotal: 1.75s\tremaining: 194ms\n",
      "18:\tlearn: 2493.5342014\ttest: 2463.6585271\tbest: 2463.6585271 (18)\ttotal: 1.84s\tremaining: 97ms\n",
      "19:\tlearn: 2453.5193400\ttest: 2425.8936331\tbest: 2425.8936331 (19)\ttotal: 1.93s\tremaining: 0us\n",
      "\n",
      "bestTest = 2425.893633\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 6165.1839504\ttest: 6116.6307948\tbest: 6116.6307948 (0)\ttotal: 109ms\tremaining: 2.07s\n",
      "1:\tlearn: 6017.1627013\ttest: 5968.4721419\tbest: 5968.4721419 (1)\ttotal: 204ms\tremaining: 1.84s\n",
      "2:\tlearn: 5874.4540326\ttest: 5825.5202327\tbest: 5825.5202327 (2)\ttotal: 300ms\tremaining: 1.7s\n",
      "3:\tlearn: 5737.0101258\ttest: 5688.0990947\tbest: 5688.0990947 (3)\ttotal: 403ms\tremaining: 1.61s\n",
      "4:\tlearn: 5603.6842196\ttest: 5555.0632892\tbest: 5555.0632892 (4)\ttotal: 513ms\tremaining: 1.54s\n",
      "5:\tlearn: 5474.8257300\ttest: 5426.2170074\tbest: 5426.2170074 (5)\ttotal: 606ms\tremaining: 1.41s\n",
      "6:\tlearn: 5351.6231707\ttest: 5302.9815553\tbest: 5302.9815553 (6)\ttotal: 714ms\tremaining: 1.33s\n",
      "7:\tlearn: 5231.1592298\ttest: 5182.3171371\tbest: 5182.3171371 (7)\ttotal: 814ms\tremaining: 1.22s\n",
      "8:\tlearn: 5115.7948805\ttest: 5066.8203287\tbest: 5066.8203287 (8)\ttotal: 904ms\tremaining: 1.1s\n",
      "9:\tlearn: 5005.1907691\ttest: 4956.1480963\tbest: 4956.1480963 (9)\ttotal: 1.01s\tremaining: 1.01s\n",
      "10:\tlearn: 4898.8666477\ttest: 4849.7669804\tbest: 4849.7669804 (10)\ttotal: 1.11s\tremaining: 911ms\n",
      "11:\tlearn: 4796.3515550\ttest: 4747.0442392\tbest: 4747.0442392 (11)\ttotal: 1.22s\tremaining: 815ms\n",
      "12:\tlearn: 4696.1848913\ttest: 4646.7017424\tbest: 4646.7017424 (12)\ttotal: 1.32s\tremaining: 712ms\n",
      "13:\tlearn: 4599.9260838\ttest: 4551.3040240\tbest: 4551.3040240 (13)\ttotal: 1.42s\tremaining: 611ms\n",
      "14:\tlearn: 4507.2683324\ttest: 4458.4668498\tbest: 4458.4668498 (14)\ttotal: 1.53s\tremaining: 511ms\n",
      "15:\tlearn: 4418.2448861\ttest: 4369.4560794\tbest: 4369.4560794 (15)\ttotal: 1.64s\tremaining: 410ms\n",
      "16:\tlearn: 4331.3562384\ttest: 4282.9126638\tbest: 4282.9126638 (16)\ttotal: 1.73s\tremaining: 306ms\n",
      "17:\tlearn: 4247.7046598\ttest: 4199.1371044\tbest: 4199.1371044 (17)\ttotal: 1.83s\tremaining: 204ms\n",
      "18:\tlearn: 4168.1389868\ttest: 4119.5586171\tbest: 4119.5586171 (18)\ttotal: 1.94s\tremaining: 102ms\n",
      "19:\tlearn: 4091.8525404\ttest: 4043.3871974\tbest: 4043.3871974 (19)\ttotal: 2.03s\tremaining: 0us\n",
      "\n",
      "bestTest = 4043.387197\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 5815.7506003\ttest: 5765.7860216\tbest: 5765.7860216 (0)\ttotal: 119ms\tremaining: 2.25s\n",
      "1:\tlearn: 5364.3458683\ttest: 5314.1188266\tbest: 5314.1188266 (1)\ttotal: 216ms\tremaining: 1.94s\n",
      "2:\tlearn: 4967.7898847\ttest: 4918.6313459\tbest: 4918.6313459 (2)\ttotal: 317ms\tremaining: 1.8s\n",
      "3:\tlearn: 4610.2407026\ttest: 4560.9657750\tbest: 4560.9657750 (3)\ttotal: 410ms\tremaining: 1.64s\n",
      "4:\tlearn: 4302.2056262\ttest: 4255.4939740\tbest: 4255.4939740 (4)\ttotal: 517ms\tremaining: 1.55s\n",
      "5:\tlearn: 4032.0453277\ttest: 3986.2465686\tbest: 3986.2465686 (5)\ttotal: 619ms\tremaining: 1.44s\n",
      "6:\tlearn: 3794.6336235\ttest: 3750.0662923\tbest: 3750.0662923 (6)\ttotal: 707ms\tremaining: 1.31s\n",
      "7:\tlearn: 3581.1989477\ttest: 3536.3464887\tbest: 3536.3464887 (7)\ttotal: 801ms\tremaining: 1.2s\n",
      "8:\tlearn: 3399.2002162\ttest: 3355.2307256\tbest: 3355.2307256 (8)\ttotal: 896ms\tremaining: 1.09s\n",
      "9:\tlearn: 3240.8411576\ttest: 3198.4190372\tbest: 3198.4190372 (9)\ttotal: 994ms\tremaining: 994ms\n",
      "10:\tlearn: 3106.6333117\ttest: 3065.7163068\tbest: 3065.7163068 (10)\ttotal: 1.1s\tremaining: 897ms\n",
      "11:\tlearn: 2985.6736894\ttest: 2945.2745355\tbest: 2945.2745355 (11)\ttotal: 1.19s\tremaining: 791ms\n",
      "12:\tlearn: 2882.4295041\ttest: 2842.6615123\tbest: 2842.6615123 (12)\ttotal: 1.27s\tremaining: 683ms\n",
      "13:\tlearn: 2793.5517548\ttest: 2756.3174262\tbest: 2756.3174262 (13)\ttotal: 1.37s\tremaining: 587ms\n",
      "14:\tlearn: 2715.4860242\ttest: 2680.1078220\tbest: 2680.1078220 (14)\ttotal: 1.46s\tremaining: 486ms\n",
      "15:\tlearn: 2647.1468277\ttest: 2613.2190267\tbest: 2613.2190267 (15)\ttotal: 1.55s\tremaining: 387ms\n",
      "16:\tlearn: 2589.4568024\ttest: 2557.0275749\tbest: 2557.0275749 (16)\ttotal: 1.64s\tremaining: 290ms\n",
      "17:\tlearn: 2538.9310940\ttest: 2507.6890851\tbest: 2507.6890851 (17)\ttotal: 1.74s\tremaining: 194ms\n",
      "18:\tlearn: 2494.0154020\ttest: 2464.0979967\tbest: 2464.0979967 (18)\ttotal: 1.82s\tremaining: 96ms\n",
      "19:\tlearn: 2453.9794498\ttest: 2426.3053848\tbest: 2426.3053848 (19)\ttotal: 1.91s\tremaining: 0us\n",
      "\n",
      "bestTest = 2426.305385\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 6160.3617784\ttest: 6111.9757036\tbest: 6111.9757036 (0)\ttotal: 345ms\tremaining: 6.54s\n",
      "1:\tlearn: 6007.9490599\ttest: 5959.5523156\tbest: 5959.5523156 (1)\ttotal: 674ms\tremaining: 6.07s\n",
      "2:\tlearn: 5860.1299770\ttest: 5812.1829696\tbest: 5812.1829696 (2)\ttotal: 977ms\tremaining: 5.54s\n",
      "3:\tlearn: 5718.2343526\ttest: 5670.2225476\tbest: 5670.2225476 (3)\ttotal: 1.31s\tremaining: 5.26s\n",
      "4:\tlearn: 5580.7386556\ttest: 5532.7469600\tbest: 5532.7469600 (4)\ttotal: 1.65s\tremaining: 4.96s\n",
      "5:\tlearn: 5446.4694233\ttest: 5398.4802623\tbest: 5398.4802623 (5)\ttotal: 1.99s\tremaining: 4.65s\n",
      "6:\tlearn: 5319.4756966\ttest: 5271.6448628\tbest: 5271.6448628 (6)\ttotal: 2.33s\tremaining: 4.33s\n",
      "7:\tlearn: 5195.5174091\ttest: 5147.8296917\tbest: 5147.8296917 (7)\ttotal: 2.67s\tremaining: 4s\n",
      "8:\tlearn: 5075.8463658\ttest: 5028.7292489\tbest: 5028.7292489 (8)\ttotal: 3s\tremaining: 3.67s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:\tlearn: 4958.9431413\ttest: 4911.7968131\tbest: 4911.7968131 (9)\ttotal: 3.34s\tremaining: 3.34s\n",
      "10:\tlearn: 4847.9686239\ttest: 4801.1614582\tbest: 4801.1614582 (10)\ttotal: 3.67s\tremaining: 3.01s\n",
      "11:\tlearn: 4739.9973919\ttest: 4693.4396735\tbest: 4693.4396735 (11)\ttotal: 4.01s\tremaining: 2.67s\n",
      "12:\tlearn: 4634.8918006\ttest: 4588.8113378\tbest: 4588.8113378 (12)\ttotal: 4.34s\tremaining: 2.33s\n",
      "13:\tlearn: 4533.5514500\ttest: 4487.9493538\tbest: 4487.9493538 (13)\ttotal: 4.67s\tremaining: 2s\n",
      "14:\tlearn: 4436.2174318\ttest: 4390.8370063\tbest: 4390.8370063 (14)\ttotal: 5s\tremaining: 1.67s\n",
      "15:\tlearn: 4343.2172602\ttest: 4298.0495443\tbest: 4298.0495443 (15)\ttotal: 5.33s\tremaining: 1.33s\n",
      "16:\tlearn: 4251.5527417\ttest: 4206.7295448\tbest: 4206.7295448 (16)\ttotal: 5.66s\tremaining: 999ms\n",
      "17:\tlearn: 4164.6175025\ttest: 4120.1229666\tbest: 4120.1229666 (17)\ttotal: 6s\tremaining: 667ms\n",
      "18:\tlearn: 4079.5213518\ttest: 4035.3703658\tbest: 4035.3703658 (18)\ttotal: 6.34s\tremaining: 334ms\n",
      "19:\tlearn: 3998.0635510\ttest: 3954.2068787\tbest: 3954.2068787 (19)\ttotal: 6.67s\tremaining: 0us\n",
      "\n",
      "bestTest = 3954.206879\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 5799.1928477\ttest: 5749.7803586\tbest: 5749.7803586 (0)\ttotal: 337ms\tremaining: 6.41s\n",
      "1:\tlearn: 5333.4603545\ttest: 5285.2104866\tbest: 5285.2104866 (1)\ttotal: 662ms\tremaining: 5.96s\n",
      "2:\tlearn: 4919.4465842\ttest: 4871.6118930\tbest: 4871.6118930 (2)\ttotal: 995ms\tremaining: 5.64s\n",
      "3:\tlearn: 4551.1319496\ttest: 4504.3780186\tbest: 4504.3780186 (3)\ttotal: 1.33s\tremaining: 5.34s\n",
      "4:\tlearn: 4230.9419609\ttest: 4184.6163531\tbest: 4184.6163531 (4)\ttotal: 1.67s\tremaining: 5s\n",
      "5:\tlearn: 3944.5721695\ttest: 3899.3880663\tbest: 3899.3880663 (5)\ttotal: 2.01s\tremaining: 4.69s\n",
      "6:\tlearn: 3693.2924742\ttest: 3649.9721783\tbest: 3649.9721783 (6)\ttotal: 2.35s\tremaining: 4.36s\n",
      "7:\tlearn: 3472.6575723\ttest: 3430.9472280\tbest: 3430.9472280 (7)\ttotal: 2.69s\tremaining: 4.04s\n",
      "8:\tlearn: 3278.8389716\ttest: 3239.5239183\tbest: 3239.5239183 (8)\ttotal: 3.04s\tremaining: 3.71s\n",
      "9:\tlearn: 3110.8282873\ttest: 3073.1528695\tbest: 3073.1528695 (9)\ttotal: 3.38s\tremaining: 3.38s\n",
      "10:\tlearn: 2964.9327574\ttest: 2930.6220562\tbest: 2930.6220562 (10)\ttotal: 3.72s\tremaining: 3.04s\n",
      "11:\tlearn: 2837.8419774\ttest: 2805.4507526\tbest: 2805.4507526 (11)\ttotal: 4.06s\tremaining: 2.7s\n",
      "12:\tlearn: 2728.4822936\ttest: 2697.8081574\tbest: 2697.8081574 (12)\ttotal: 4.39s\tremaining: 2.36s\n",
      "13:\tlearn: 2632.7388735\ttest: 2603.8200106\tbest: 2603.8200106 (13)\ttotal: 4.73s\tremaining: 2.03s\n",
      "14:\tlearn: 2551.5207672\ttest: 2523.9011378\tbest: 2523.9011378 (14)\ttotal: 5.07s\tremaining: 1.69s\n",
      "15:\tlearn: 2479.0023661\ttest: 2453.4202692\tbest: 2453.4202692 (15)\ttotal: 5.4s\tremaining: 1.35s\n",
      "16:\tlearn: 2419.7241987\ttest: 2396.3235142\tbest: 2396.3235142 (16)\ttotal: 5.73s\tremaining: 1.01s\n",
      "17:\tlearn: 2365.7490603\ttest: 2344.6571374\tbest: 2344.6571374 (17)\ttotal: 6.08s\tremaining: 675ms\n",
      "18:\tlearn: 2314.4479953\ttest: 2295.1121470\tbest: 2295.1121470 (18)\ttotal: 6.4s\tremaining: 337ms\n",
      "19:\tlearn: 2272.2558188\ttest: 2254.5911427\tbest: 2254.5911427 (19)\ttotal: 6.74s\tremaining: 0us\n",
      "\n",
      "bestTest = 2254.591143\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 6161.1199037\ttest: 6112.7468022\tbest: 6112.7468022 (0)\ttotal: 342ms\tremaining: 6.5s\n",
      "1:\tlearn: 6008.8752868\ttest: 5960.4976487\tbest: 5960.4976487 (1)\ttotal: 671ms\tremaining: 6.04s\n",
      "2:\tlearn: 5861.2861464\ttest: 5813.3793773\tbest: 5813.3793773 (2)\ttotal: 1s\tremaining: 5.69s\n",
      "3:\tlearn: 5719.6383535\ttest: 5671.6762130\tbest: 5671.6762130 (3)\ttotal: 1.34s\tremaining: 5.37s\n",
      "4:\tlearn: 5582.7692541\ttest: 5534.8352228\tbest: 5534.8352228 (4)\ttotal: 1.68s\tremaining: 5.04s\n",
      "5:\tlearn: 5448.6018465\ttest: 5400.6679460\tbest: 5400.6679460 (5)\ttotal: 2s\tremaining: 4.66s\n",
      "6:\tlearn: 5321.8341803\ttest: 5274.0556702\tbest: 5274.0556702 (6)\ttotal: 2.34s\tremaining: 4.35s\n",
      "7:\tlearn: 5198.1424539\ttest: 5150.5098339\tbest: 5150.5098339 (7)\ttotal: 2.68s\tremaining: 4.01s\n",
      "8:\tlearn: 5078.7936200\ttest: 5031.7256727\tbest: 5031.7256727 (8)\ttotal: 3.02s\tremaining: 3.69s\n",
      "9:\tlearn: 4962.1153085\ttest: 4915.0271964\tbest: 4915.0271964 (9)\ttotal: 3.35s\tremaining: 3.35s\n",
      "10:\tlearn: 4851.4077297\ttest: 4804.6464371\tbest: 4804.6464371 (10)\ttotal: 3.69s\tremaining: 3.02s\n",
      "11:\tlearn: 4743.7084315\ttest: 4697.0771717\tbest: 4697.0771717 (11)\ttotal: 4.02s\tremaining: 2.68s\n",
      "12:\tlearn: 4638.6449501\ttest: 4592.4858959\tbest: 4592.4858959 (12)\ttotal: 4.36s\tremaining: 2.35s\n",
      "13:\tlearn: 4537.3648800\ttest: 4491.6798849\tbest: 4491.6798849 (13)\ttotal: 4.68s\tremaining: 2s\n",
      "14:\tlearn: 4440.1951142\ttest: 4394.7346957\tbest: 4394.7346957 (14)\ttotal: 5s\tremaining: 1.67s\n",
      "15:\tlearn: 4347.6098407\ttest: 4302.3149810\tbest: 4302.3149810 (15)\ttotal: 5.34s\tremaining: 1.33s\n",
      "16:\tlearn: 4256.0481326\ttest: 4211.0870775\tbest: 4211.0870775 (16)\ttotal: 5.68s\tremaining: 1s\n",
      "17:\tlearn: 4169.4641442\ttest: 4124.8239191\tbest: 4124.8239191 (17)\ttotal: 6.01s\tremaining: 668ms\n",
      "18:\tlearn: 4084.3293145\ttest: 4040.0513033\tbest: 4040.0513033 (18)\ttotal: 6.34s\tremaining: 334ms\n",
      "19:\tlearn: 4003.0016115\ttest: 3959.0004498\tbest: 3959.0004498 (19)\ttotal: 6.68s\tremaining: 0us\n",
      "\n",
      "bestTest = 3959.00045\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 5801.6917902\ttest: 5752.3224234\tbest: 5752.3224234 (0)\ttotal: 326ms\tremaining: 6.2s\n",
      "1:\tlearn: 5336.3088920\ttest: 5288.1213796\tbest: 5288.1213796 (1)\ttotal: 660ms\tremaining: 5.94s\n",
      "2:\tlearn: 4922.7210523\ttest: 4874.9088166\tbest: 4874.9088166 (2)\ttotal: 993ms\tremaining: 5.63s\n",
      "3:\tlearn: 4554.4827250\ttest: 4507.7366435\tbest: 4507.7366435 (3)\ttotal: 1.32s\tremaining: 5.28s\n",
      "4:\tlearn: 4235.4042049\ttest: 4189.0632970\tbest: 4189.0632970 (4)\ttotal: 1.66s\tremaining: 4.97s\n",
      "5:\tlearn: 3949.0300818\ttest: 3903.8063257\tbest: 3903.8063257 (5)\ttotal: 1.99s\tremaining: 4.64s\n",
      "6:\tlearn: 3697.6464609\ttest: 3654.2546289\tbest: 3654.2546289 (6)\ttotal: 2.33s\tremaining: 4.32s\n",
      "7:\tlearn: 3480.6461574\ttest: 3439.0050432\tbest: 3439.0050432 (7)\ttotal: 2.67s\tremaining: 4s\n",
      "8:\tlearn: 3286.4515652\ttest: 3247.1619424\tbest: 3247.1619424 (8)\ttotal: 3s\tremaining: 3.67s\n",
      "9:\tlearn: 3117.4524583\ttest: 3079.7668031\tbest: 3079.7668031 (9)\ttotal: 3.34s\tremaining: 3.34s\n",
      "10:\tlearn: 2971.8732765\ttest: 2936.7521338\tbest: 2936.7521338 (10)\ttotal: 3.67s\tremaining: 3s\n",
      "11:\tlearn: 2844.3710128\ttest: 2810.6217099\tbest: 2810.6217099 (11)\ttotal: 4.01s\tremaining: 2.67s\n",
      "12:\tlearn: 2734.8031026\ttest: 2703.3948102\tbest: 2703.3948102 (12)\ttotal: 4.34s\tremaining: 2.33s\n",
      "13:\tlearn: 2638.3983275\ttest: 2608.7691732\tbest: 2608.7691732 (13)\ttotal: 4.67s\tremaining: 2s\n",
      "14:\tlearn: 2556.3191650\ttest: 2528.3255146\tbest: 2528.3255146 (14)\ttotal: 5s\tremaining: 1.67s\n",
      "15:\tlearn: 2485.4551955\ttest: 2458.8449362\tbest: 2458.8449362 (15)\ttotal: 5.33s\tremaining: 1.33s\n",
      "16:\tlearn: 2423.3695727\ttest: 2398.2595320\tbest: 2398.2595320 (16)\ttotal: 5.67s\tremaining: 1s\n",
      "17:\tlearn: 2370.6228697\ttest: 2348.1451553\tbest: 2348.1451553 (17)\ttotal: 6s\tremaining: 667ms\n",
      "18:\tlearn: 2325.6699069\ttest: 2304.4361764\tbest: 2304.4361764 (18)\ttotal: 6.34s\tremaining: 334ms\n",
      "19:\tlearn: 2283.5970126\ttest: 2264.1690266\tbest: 2264.1690266 (19)\ttotal: 6.65s\tremaining: 0us\n",
      "\n",
      "bestTest = 2264.169027\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 6161.8484336\ttest: 6113.4872170\tbest: 6113.4872170 (0)\ttotal: 337ms\tremaining: 6.41s\n",
      "1:\tlearn: 6009.7694171\ttest: 5961.4096061\tbest: 5961.4096061 (1)\ttotal: 664ms\tremaining: 5.97s\n",
      "2:\tlearn: 5862.4051556\ttest: 5814.5330878\tbest: 5814.5330878 (2)\ttotal: 997ms\tremaining: 5.65s\n",
      "3:\tlearn: 5721.0005471\ttest: 5673.0815507\tbest: 5673.0815507 (3)\ttotal: 1.34s\tremaining: 5.36s\n",
      "4:\tlearn: 5584.7188612\ttest: 5536.8305406\tbest: 5536.8305406 (4)\ttotal: 1.68s\tremaining: 5.04s\n",
      "5:\tlearn: 5450.6535940\ttest: 5402.7632911\tbest: 5402.7632911 (5)\ttotal: 2.02s\tremaining: 4.71s\n",
      "6:\tlearn: 5321.5308256\ttest: 5273.7566642\tbest: 5273.7566642 (6)\ttotal: 2.36s\tremaining: 4.38s\n",
      "7:\tlearn: 5198.2148178\ttest: 5150.5883137\tbest: 5150.5883137 (7)\ttotal: 2.69s\tremaining: 4.03s\n",
      "8:\tlearn: 5079.2014483\ttest: 5032.1327114\tbest: 5032.1327114 (8)\ttotal: 3.03s\tremaining: 3.7s\n",
      "9:\tlearn: 4962.8948385\ttest: 4915.8120882\tbest: 4915.8120882 (9)\ttotal: 3.37s\tremaining: 3.37s\n",
      "10:\tlearn: 4852.5307754\ttest: 4805.7646387\tbest: 4805.7646387 (10)\ttotal: 3.69s\tremaining: 3.02s\n",
      "11:\tlearn: 4744.9898885\ttest: 4698.3487691\tbest: 4698.3487691 (11)\ttotal: 4.02s\tremaining: 2.68s\n",
      "12:\tlearn: 4639.5842905\ttest: 4593.4311209\tbest: 4593.4311209 (12)\ttotal: 4.35s\tremaining: 2.34s\n",
      "13:\tlearn: 4538.4029560\ttest: 4492.7150905\tbest: 4492.7150905 (13)\ttotal: 4.68s\tremaining: 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:\tlearn: 4441.5592715\ttest: 4396.0930258\tbest: 4396.0930258 (14)\ttotal: 5s\tremaining: 1.67s\n",
      "15:\tlearn: 4348.0991594\ttest: 4302.9853796\tbest: 4302.9853796 (15)\ttotal: 5.33s\tremaining: 1.33s\n",
      "16:\tlearn: 4256.8261015\ttest: 4212.0286885\tbest: 4212.0286885 (16)\ttotal: 5.67s\tremaining: 1s\n",
      "17:\tlearn: 4170.6221923\ttest: 4126.1321450\tbest: 4126.1321450 (17)\ttotal: 5.99s\tremaining: 666ms\n",
      "18:\tlearn: 4085.6007858\ttest: 4041.4419163\tbest: 4041.4419163 (18)\ttotal: 6.33s\tremaining: 333ms\n",
      "19:\tlearn: 4004.8170647\ttest: 3960.8867076\tbest: 3960.8867076 (19)\ttotal: 6.66s\tremaining: 0us\n",
      "\n",
      "bestTest = 3960.886708\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 5804.0948603\ttest: 5754.7651164\tbest: 5754.7651164 (0)\ttotal: 330ms\tremaining: 6.26s\n",
      "1:\tlearn: 5339.0589627\ttest: 5290.9295410\tbest: 5290.9295410 (1)\ttotal: 664ms\tremaining: 5.98s\n",
      "2:\tlearn: 4925.8966431\ttest: 4878.1047752\tbest: 4878.1047752 (2)\ttotal: 998ms\tremaining: 5.65s\n",
      "3:\tlearn: 4557.7416983\ttest: 4511.0021144\tbest: 4511.0021144 (3)\ttotal: 1.34s\tremaining: 5.36s\n",
      "4:\tlearn: 4239.7068054\ttest: 4193.3499193\tbest: 4193.3499193 (4)\ttotal: 1.67s\tremaining: 5s\n",
      "5:\tlearn: 3953.3371023\ttest: 3908.0754898\tbest: 3908.0754898 (5)\ttotal: 2s\tremaining: 4.67s\n",
      "6:\tlearn: 3701.8651600\ttest: 3658.4071909\tbest: 3658.4071909 (6)\ttotal: 2.34s\tremaining: 4.35s\n",
      "7:\tlearn: 3485.4376436\ttest: 3443.7665494\tbest: 3443.7665494 (7)\ttotal: 2.68s\tremaining: 4.02s\n",
      "8:\tlearn: 3291.3532541\ttest: 3251.9880865\tbest: 3251.9880865 (8)\ttotal: 3.01s\tremaining: 3.68s\n",
      "9:\tlearn: 3122.1621283\ttest: 3084.3689842\tbest: 3084.3689842 (9)\ttotal: 3.35s\tremaining: 3.35s\n",
      "10:\tlearn: 2975.9250793\ttest: 2940.6807804\tbest: 2940.6807804 (10)\ttotal: 3.67s\tremaining: 3.01s\n",
      "11:\tlearn: 2849.2733764\ttest: 2815.7070066\tbest: 2815.7070066 (11)\ttotal: 4.01s\tremaining: 2.67s\n",
      "12:\tlearn: 2739.2211075\ttest: 2707.7483643\tbest: 2707.7483643 (12)\ttotal: 4.34s\tremaining: 2.34s\n",
      "13:\tlearn: 2644.8147290\ttest: 2614.3504230\tbest: 2614.3504230 (13)\ttotal: 4.68s\tremaining: 2.01s\n",
      "14:\tlearn: 2563.3421192\ttest: 2534.6872784\tbest: 2534.6872784 (14)\ttotal: 5.03s\tremaining: 1.68s\n",
      "15:\tlearn: 2491.0833091\ttest: 2464.2209912\tbest: 2464.2209912 (15)\ttotal: 5.37s\tremaining: 1.34s\n",
      "16:\tlearn: 2426.2611563\ttest: 2400.7502763\tbest: 2400.7502763 (16)\ttotal: 5.71s\tremaining: 1.01s\n",
      "17:\tlearn: 2373.2735844\ttest: 2350.9318156\tbest: 2350.9318156 (17)\ttotal: 6.05s\tremaining: 672ms\n",
      "18:\tlearn: 2326.3789116\ttest: 2305.6093508\tbest: 2305.6093508 (18)\ttotal: 6.38s\tremaining: 336ms\n",
      "19:\tlearn: 2284.4784745\ttest: 2265.3905605\tbest: 2265.3905605 (19)\ttotal: 6.71s\tremaining: 0us\n",
      "\n",
      "bestTest = 2265.39056\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 6162.5519946\ttest: 6114.2017696\tbest: 6114.2017696 (0)\ttotal: 342ms\tremaining: 6.5s\n",
      "1:\tlearn: 6010.6361829\ttest: 5962.2931211\tbest: 5962.2931211 (1)\ttotal: 661ms\tremaining: 5.95s\n",
      "2:\tlearn: 5863.4922881\ttest: 5815.6507592\tbest: 5815.6507592 (2)\ttotal: 986ms\tremaining: 5.59s\n",
      "3:\tlearn: 5722.3266115\ttest: 5674.4457773\tbest: 5674.4457773 (3)\ttotal: 1.3s\tremaining: 5.22s\n",
      "4:\tlearn: 5586.6017873\ttest: 5538.7520572\tbest: 5538.7520572 (4)\ttotal: 1.64s\tremaining: 4.93s\n",
      "5:\tlearn: 5452.6386328\ttest: 5404.7849739\tbest: 5404.7849739 (5)\ttotal: 1.97s\tremaining: 4.59s\n",
      "6:\tlearn: 5326.2958821\ttest: 5278.5962371\tbest: 5278.5962371 (6)\ttotal: 2.3s\tremaining: 4.28s\n",
      "7:\tlearn: 5203.1245212\ttest: 5155.5753852\tbest: 5155.5753852 (7)\ttotal: 2.64s\tremaining: 3.96s\n",
      "8:\tlearn: 5084.3891942\ttest: 5037.3918756\tbest: 5037.3918756 (8)\ttotal: 2.97s\tremaining: 3.63s\n",
      "9:\tlearn: 4968.1420795\ttest: 4921.1405977\tbest: 4921.1405977 (9)\ttotal: 3.31s\tremaining: 3.31s\n",
      "10:\tlearn: 4857.9407446\ttest: 4811.2469443\tbest: 4811.2469443 (10)\ttotal: 3.64s\tremaining: 2.98s\n",
      "11:\tlearn: 4750.4300726\ttest: 4703.8572831\tbest: 4703.8572831 (11)\ttotal: 3.98s\tremaining: 2.65s\n",
      "12:\tlearn: 4645.5641217\ttest: 4599.4561935\tbest: 4599.4561935 (12)\ttotal: 4.32s\tremaining: 2.32s\n",
      "13:\tlearn: 4544.4402792\ttest: 4498.7948622\tbest: 4498.7948622 (13)\ttotal: 4.65s\tremaining: 1.99s\n",
      "14:\tlearn: 4447.7994478\ttest: 4402.2923194\tbest: 4402.2923194 (14)\ttotal: 4.99s\tremaining: 1.66s\n",
      "15:\tlearn: 4355.4079401\ttest: 4310.0698978\tbest: 4310.0698978 (15)\ttotal: 5.33s\tremaining: 1.33s\n",
      "16:\tlearn: 4263.9702174\ttest: 4218.9551428\tbest: 4218.9551428 (16)\ttotal: 5.66s\tremaining: 1000ms\n",
      "17:\tlearn: 4177.5519395\ttest: 4133.3191343\tbest: 4133.3191343 (17)\ttotal: 6.01s\tremaining: 668ms\n",
      "18:\tlearn: 4092.4265694\ttest: 4048.4863259\tbest: 4048.4863259 (18)\ttotal: 6.37s\tremaining: 335ms\n",
      "19:\tlearn: 4011.5777126\ttest: 3967.8520195\tbest: 3967.8520195 (19)\ttotal: 6.71s\tremaining: 0us\n",
      "\n",
      "bestTest = 3967.85202\n",
      "bestIteration = 19\n",
      "\n",
      "0:\tlearn: 5806.4168363\ttest: 5757.1237854\tbest: 5757.1237854 (0)\ttotal: 347ms\tremaining: 6.59s\n",
      "1:\tlearn: 5341.7250267\ttest: 5293.6499110\tbest: 5293.6499110 (1)\ttotal: 676ms\tremaining: 6.08s\n",
      "2:\tlearn: 4928.9870012\ttest: 4881.2136436\tbest: 4881.2136436 (2)\ttotal: 1.01s\tremaining: 5.74s\n",
      "3:\tlearn: 4560.9211344\ttest: 4514.1866999\tbest: 4514.1866999 (3)\ttotal: 1.35s\tremaining: 5.39s\n",
      "4:\tlearn: 4243.8772987\ttest: 4197.5040555\tbest: 4197.5040555 (4)\ttotal: 1.69s\tremaining: 5.06s\n",
      "5:\tlearn: 3957.5186828\ttest: 3912.2205988\tbest: 3912.2205988 (5)\ttotal: 2.02s\tremaining: 4.71s\n",
      "6:\tlearn: 3705.9707017\ttest: 3662.4507225\tbest: 3662.4507225 (6)\ttotal: 2.36s\tremaining: 4.38s\n",
      "7:\tlearn: 3490.0874494\ttest: 3448.3868512\tbest: 3448.3868512 (7)\ttotal: 2.7s\tremaining: 4.05s\n",
      "8:\tlearn: 3296.1039705\ttest: 3256.6685365\tbest: 3256.6685365 (8)\ttotal: 3.04s\tremaining: 3.71s\n",
      "9:\tlearn: 3124.9579980\ttest: 3087.0248072\tbest: 3087.0248072 (9)\ttotal: 3.37s\tremaining: 3.37s\n",
      "10:\tlearn: 2978.9053947\ttest: 2943.1963339\tbest: 2943.1963339 (10)\ttotal: 3.7s\tremaining: 3.03s\n",
      "11:\tlearn: 2852.4936349\ttest: 2818.4249560\tbest: 2818.4249560 (11)\ttotal: 4.03s\tremaining: 2.69s\n",
      "12:\tlearn: 2744.1253286\ttest: 2712.2383770\tbest: 2712.2383770 (12)\ttotal: 4.38s\tremaining: 2.36s\n",
      "13:\tlearn: 2647.9536045\ttest: 2617.7877512\tbest: 2617.7877512 (13)\ttotal: 4.72s\tremaining: 2.02s\n",
      "14:\tlearn: 2565.7257174\ttest: 2537.4558436\tbest: 2537.4558436 (14)\ttotal: 5.06s\tremaining: 1.69s\n",
      "15:\tlearn: 2495.7941237\ttest: 2468.9011678\tbest: 2468.9011678 (15)\ttotal: 5.39s\tremaining: 1.35s\n",
      "16:\tlearn: 2434.7699190\ttest: 2410.5970112\tbest: 2410.5970112 (16)\ttotal: 5.73s\tremaining: 1.01s\n",
      "17:\tlearn: 2376.2061308\ttest: 2354.2452427\tbest: 2354.2452427 (17)\ttotal: 6.07s\tremaining: 674ms\n",
      "18:\tlearn: 2328.9656239\ttest: 2308.1076144\tbest: 2308.1076144 (18)\ttotal: 6.4s\tremaining: 337ms\n",
      "19:\tlearn: 2285.4594671\ttest: 2266.4186179\tbest: 2266.4186179 (19)\ttotal: 6.73s\tremaining: 0us\n",
      "\n",
      "bestTest = 2266.418618\n",
      "bestIteration = 19\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 5782.2080525\ttest: 5808.2303144\tbest: 5808.2303144 (0)\ttotal: 255ms\tremaining: 4.84s\n",
      "1:\tlearn: 5318.7104698\ttest: 5344.7624558\tbest: 5344.7624558 (1)\ttotal: 503ms\tremaining: 4.53s\n",
      "2:\tlearn: 4906.2066967\ttest: 4933.8537254\tbest: 4933.8537254 (2)\ttotal: 759ms\tremaining: 4.3s\n",
      "3:\tlearn: 4544.3024963\ttest: 4573.7744386\tbest: 4573.7744386 (3)\ttotal: 1.02s\tremaining: 4.07s\n",
      "4:\tlearn: 4221.0559910\ttest: 4251.2215677\tbest: 4251.2215677 (4)\ttotal: 1.27s\tremaining: 3.81s\n",
      "5:\tlearn: 3935.8258038\ttest: 3966.6104276\tbest: 3966.6104276 (5)\ttotal: 1.52s\tremaining: 3.55s\n",
      "6:\tlearn: 3686.0756070\ttest: 3717.8343292\tbest: 3717.8343292 (6)\ttotal: 1.78s\tremaining: 3.3s\n",
      "7:\tlearn: 3460.4966572\ttest: 3493.3188405\tbest: 3493.3188405 (7)\ttotal: 2.03s\tremaining: 3.04s\n",
      "8:\tlearn: 3267.1006747\ttest: 3301.1819113\tbest: 3301.1819113 (8)\ttotal: 2.28s\tremaining: 2.79s\n",
      "9:\tlearn: 3097.8292980\ttest: 3132.9455724\tbest: 3132.9455724 (9)\ttotal: 2.53s\tremaining: 2.53s\n",
      "10:\tlearn: 2953.3659139\ttest: 2989.7378039\tbest: 2989.7378039 (10)\ttotal: 2.78s\tremaining: 2.28s\n",
      "11:\tlearn: 2828.2610495\ttest: 2865.8988533\tbest: 2865.8988533 (11)\ttotal: 3.04s\tremaining: 2.03s\n",
      "12:\tlearn: 2716.2868124\ttest: 2755.3168752\tbest: 2755.3168752 (12)\ttotal: 3.29s\tremaining: 1.77s\n",
      "13:\tlearn: 2620.3937114\ttest: 2660.0675426\tbest: 2660.0675426 (13)\ttotal: 3.54s\tremaining: 1.52s\n",
      "14:\tlearn: 2539.4406822\ttest: 2580.4183570\tbest: 2580.4183570 (14)\ttotal: 3.79s\tremaining: 1.26s\n",
      "15:\tlearn: 2470.2843402\ttest: 2512.3744288\tbest: 2512.3744288 (15)\ttotal: 4.04s\tremaining: 1.01s\n",
      "16:\tlearn: 2407.5258535\ttest: 2450.7479483\tbest: 2450.7479483 (16)\ttotal: 4.29s\tremaining: 757ms\n",
      "17:\tlearn: 2348.7151551\ttest: 2392.4660317\tbest: 2392.4660317 (17)\ttotal: 4.55s\tremaining: 505ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:\tlearn: 2301.0454501\ttest: 2345.7263519\tbest: 2345.7263519 (18)\ttotal: 4.8s\tremaining: 253ms\n",
      "19:\tlearn: 2261.2819411\ttest: 2306.5406966\tbest: 2306.5406966 (19)\ttotal: 5.05s\tremaining: 0us\n",
      "\n",
      "bestTest = 2306.540697\n",
      "bestIteration = 19\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 5789.8603009\ttest: 5772.0886178\tbest: 5772.0886178 (0)\ttotal: 259ms\tremaining: 4.92s\n",
      "1:\tlearn: 5331.5755873\ttest: 5314.5033186\tbest: 5314.5033186 (1)\ttotal: 516ms\tremaining: 4.64s\n",
      "2:\tlearn: 4919.2356948\ttest: 4903.1632505\tbest: 4903.1632505 (2)\ttotal: 770ms\tremaining: 4.37s\n",
      "3:\tlearn: 4554.9768335\ttest: 4540.3342139\tbest: 4540.3342139 (3)\ttotal: 1.03s\tremaining: 4.12s\n",
      "4:\tlearn: 4231.9570745\ttest: 4218.2005177\tbest: 4218.2005177 (4)\ttotal: 1.3s\tremaining: 3.91s\n",
      "5:\tlearn: 3946.4676025\ttest: 3933.4693605\tbest: 3933.4693605 (5)\ttotal: 1.55s\tremaining: 3.63s\n",
      "6:\tlearn: 3696.9702313\ttest: 3684.7175157\tbest: 3684.7175157 (6)\ttotal: 1.81s\tremaining: 3.37s\n",
      "7:\tlearn: 3478.4570516\ttest: 3466.1140618\tbest: 3466.1140618 (7)\ttotal: 2.07s\tremaining: 3.1s\n",
      "8:\tlearn: 3285.7876374\ttest: 3273.5865311\tbest: 3273.5865311 (8)\ttotal: 2.32s\tremaining: 2.84s\n",
      "9:\tlearn: 3114.3403072\ttest: 3103.3925986\tbest: 3103.3925986 (9)\ttotal: 2.57s\tremaining: 2.57s\n",
      "10:\tlearn: 2965.3063057\ttest: 2955.0576432\tbest: 2955.0576432 (10)\ttotal: 2.83s\tremaining: 2.31s\n",
      "11:\tlearn: 2839.4262034\ttest: 2829.6485175\tbest: 2829.6485175 (11)\ttotal: 3.08s\tremaining: 2.06s\n",
      "12:\tlearn: 2727.2750165\ttest: 2718.5334386\tbest: 2718.5334386 (12)\ttotal: 3.33s\tremaining: 1.79s\n",
      "13:\tlearn: 2634.1467249\ttest: 2626.3094807\tbest: 2626.3094807 (13)\ttotal: 3.59s\tremaining: 1.54s\n",
      "14:\tlearn: 2548.3849740\ttest: 2542.4050994\tbest: 2542.4050994 (14)\ttotal: 3.85s\tremaining: 1.28s\n",
      "15:\tlearn: 2476.6698343\ttest: 2471.7199588\tbest: 2471.7199588 (15)\ttotal: 4.1s\tremaining: 1.02s\n",
      "16:\tlearn: 2409.8446493\ttest: 2406.1738981\tbest: 2406.1738981 (16)\ttotal: 4.34s\tremaining: 766ms\n",
      "17:\tlearn: 2353.6845581\ttest: 2350.6605016\tbest: 2350.6605016 (17)\ttotal: 4.6s\tremaining: 511ms\n",
      "18:\tlearn: 2306.0013918\ttest: 2303.6064202\tbest: 2303.6064202 (18)\ttotal: 4.85s\tremaining: 255ms\n",
      "19:\tlearn: 2265.5705771\ttest: 2264.7786842\tbest: 2264.7786842 (19)\ttotal: 5.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 2264.778684\n",
      "bestIteration = 19\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 5793.4216390\ttest: 5784.8335324\tbest: 5784.8335324 (0)\ttotal: 255ms\tremaining: 4.84s\n",
      "1:\tlearn: 5330.3456336\ttest: 5321.4930687\tbest: 5321.4930687 (1)\ttotal: 513ms\tremaining: 4.61s\n",
      "2:\tlearn: 4919.6185792\ttest: 4911.1760683\tbest: 4911.1760683 (2)\ttotal: 763ms\tremaining: 4.33s\n",
      "3:\tlearn: 4555.4718274\ttest: 4546.9288044\tbest: 4546.9288044 (3)\ttotal: 1.02s\tremaining: 4.07s\n",
      "4:\tlearn: 4233.8448229\ttest: 4225.2524788\tbest: 4225.2524788 (4)\ttotal: 1.27s\tremaining: 3.81s\n",
      "5:\tlearn: 3948.2403662\ttest: 3939.2912596\tbest: 3939.2912596 (5)\ttotal: 1.52s\tremaining: 3.56s\n",
      "6:\tlearn: 3697.3652648\ttest: 3689.1209581\tbest: 3689.1209581 (6)\ttotal: 1.78s\tremaining: 3.31s\n",
      "7:\tlearn: 3476.7702982\ttest: 3468.7670288\tbest: 3468.7670288 (7)\ttotal: 2.04s\tremaining: 3.06s\n",
      "8:\tlearn: 3284.3915056\ttest: 3276.3720987\tbest: 3276.3720987 (8)\ttotal: 2.29s\tremaining: 2.8s\n",
      "9:\tlearn: 3115.7828403\ttest: 3106.4023875\tbest: 3106.4023875 (9)\ttotal: 2.54s\tremaining: 2.54s\n",
      "10:\tlearn: 2972.2982289\ttest: 2962.7876495\tbest: 2962.7876495 (10)\ttotal: 2.79s\tremaining: 2.28s\n",
      "11:\tlearn: 2844.5155096\ttest: 2835.5350411\tbest: 2835.5350411 (11)\ttotal: 3.04s\tremaining: 2.03s\n",
      "12:\tlearn: 2736.0341568\ttest: 2726.9502137\tbest: 2726.9502137 (12)\ttotal: 3.29s\tremaining: 1.77s\n",
      "13:\tlearn: 2643.0650664\ttest: 2634.2029503\tbest: 2634.2029503 (13)\ttotal: 3.54s\tremaining: 1.52s\n",
      "14:\tlearn: 2561.5934824\ttest: 2552.2246235\tbest: 2552.2246235 (14)\ttotal: 3.81s\tremaining: 1.27s\n",
      "15:\tlearn: 2491.4642081\ttest: 2482.7691966\tbest: 2482.7691966 (15)\ttotal: 4.06s\tremaining: 1.01s\n",
      "16:\tlearn: 2427.0067324\ttest: 2418.4690168\tbest: 2418.4690168 (16)\ttotal: 4.32s\tremaining: 763ms\n",
      "17:\tlearn: 2367.7325547\ttest: 2358.9173602\tbest: 2358.9173602 (17)\ttotal: 4.58s\tremaining: 509ms\n",
      "18:\tlearn: 2319.8554375\ttest: 2310.5758635\tbest: 2310.5758635 (18)\ttotal: 4.83s\tremaining: 254ms\n",
      "19:\tlearn: 2280.1565736\ttest: 2270.9322873\tbest: 2270.9322873 (19)\ttotal: 5.08s\tremaining: 0us\n",
      "\n",
      "bestTest = 2270.932287\n",
      "bestIteration = 19\n",
      "\n",
      "Best validation RMSE score : 2280.750622.5458 on step 19\n"
     ]
    }
   ],
   "source": [
    "# Grid search for CatBoost\n",
    "param_grid = {\n",
    "    'learning_rate': [0.03, 0.1],\n",
    "    'depth': [6, 10],\n",
    "    'l2_leaf_reg': [3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "model = CatBoostRegressor(iterations=20, loss_function='RMSE', task_type=\"CPU\", random_seed=random_state)\n",
    "grid_search_result = model.grid_search(param_grid, \n",
    "                                       train_ds,\n",
    "                                       verbose=0,\n",
    "                                       partition_random_seed=random_state,\n",
    "                                       search_by_train_test_split=True,\n",
    "                                       train_size=0.9)\n",
    "\n",
    "# Extracting the best parameters and results\n",
    "cv_data = pd.DataFrame(grid_search_result[\"cv_results\"])\n",
    "best_value = cv_data['test-RMSE-mean'].min()\n",
    "best_iter = cv_data['test-RMSE-mean'].idxmin()\n",
    "\n",
    "print('Best validation RMSE score : {:.4f}{:.4f} on step {}'.format(\n",
    "    best_value,\n",
    "    cv_data['test-RMSE-std'][best_iter],\n",
    "    best_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4204.1274364\ttest: 4228.7330592\tbest: 4228.7330592 (0)\ttotal: 369ms\tremaining: 7.01s\n",
      "1:\tlearn: 3936.3128497\ttest: 3958.4504005\tbest: 3958.4504005 (1)\ttotal: 732ms\tremaining: 6.59s\n",
      "2:\tlearn: 3703.9167584\ttest: 3725.4549272\tbest: 3725.4549272 (2)\ttotal: 1.11s\tremaining: 6.31s\n",
      "3:\tlearn: 3494.4131843\ttest: 3515.8132387\tbest: 3515.8132387 (3)\ttotal: 1.48s\tremaining: 5.92s\n",
      "4:\tlearn: 3308.8290352\ttest: 3329.9062019\tbest: 3329.9062019 (4)\ttotal: 1.84s\tremaining: 5.54s\n",
      "5:\tlearn: 3146.9306704\ttest: 3168.3611120\tbest: 3168.3611120 (5)\ttotal: 2.22s\tremaining: 5.17s\n",
      "6:\tlearn: 3004.3502339\ttest: 3026.5960795\tbest: 3026.5960795 (6)\ttotal: 2.58s\tremaining: 4.8s\n",
      "7:\tlearn: 2886.5476515\ttest: 2910.0927432\tbest: 2910.0927432 (7)\ttotal: 2.95s\tremaining: 4.43s\n",
      "8:\tlearn: 2778.1632453\ttest: 2803.6869421\tbest: 2803.6869421 (8)\ttotal: 3.31s\tremaining: 4.05s\n",
      "9:\tlearn: 2681.5480698\ttest: 2706.9961713\tbest: 2706.9961713 (9)\ttotal: 3.69s\tremaining: 3.69s\n",
      "10:\tlearn: 2601.8664313\ttest: 2627.6754376\tbest: 2627.6754376 (10)\ttotal: 4.05s\tremaining: 3.32s\n",
      "11:\tlearn: 2532.1277836\ttest: 2559.3978481\tbest: 2559.3978481 (11)\ttotal: 4.43s\tremaining: 2.95s\n",
      "12:\tlearn: 2470.6464082\ttest: 2498.3729386\tbest: 2498.3729386 (12)\ttotal: 4.8s\tremaining: 2.59s\n",
      "13:\tlearn: 2416.4742879\ttest: 2444.1703446\tbest: 2444.1703446 (13)\ttotal: 5.18s\tremaining: 2.22s\n",
      "14:\tlearn: 2370.0189585\ttest: 2398.4432055\tbest: 2398.4432055 (14)\ttotal: 5.55s\tremaining: 1.85s\n",
      "15:\tlearn: 2326.1509491\ttest: 2356.1791467\tbest: 2356.1791467 (15)\ttotal: 5.93s\tremaining: 1.48s\n",
      "16:\tlearn: 2289.0469661\ttest: 2319.6115239\tbest: 2319.6115239 (16)\ttotal: 6.3s\tremaining: 1.11s\n",
      "17:\tlearn: 2256.0781999\ttest: 2287.5900096\tbest: 2287.5900096 (17)\ttotal: 6.66s\tremaining: 740ms\n",
      "18:\tlearn: 2226.9079579\ttest: 2259.0468695\tbest: 2259.0468695 (18)\ttotal: 7.04s\tremaining: 370ms\n",
      "19:\tlearn: 2200.8229176\ttest: 2232.8505403\tbest: 2232.8505403 (19)\ttotal: 7.4s\tremaining: 0us\n",
      "\n",
      "bestTest = 2232.85054\n",
      "bestIteration = 19\n",
      "\n",
      "CatBoost (tuned) RMSE: 2232.850540288301\n",
      "CatBoost (tuned) Fit time: 8.277621507644653 seconds, Predict time: 0.007220268249511719 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train final CatBoost model with best parameters\n",
    "model = CatBoostRegressor(iterations=20, loss_function='RMSE', task_type=\"CPU\", random_seed=random_state, **grid_search_result[\"params\"])\n",
    "start_fit = time.time()\n",
    "model.fit(train_ds, verbose=1, eval_set=[(X_test, y_test)], use_best_model=True)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_predict = time.time()\n",
    "y_pred = model.predict(test_ds)\n",
    "predict_time = time.time() - start_predict\n",
    "\n",
    "rmse = rmse_func(y_test, y_pred)\n",
    "print(f\"CatBoost (tuned) RMSE: {rmse}\")\n",
    "print(f\"CatBoost (tuned) Fit time: {fit_time} seconds, Predict time: {predict_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE: 1771.195953679433\n",
      "XGBoost Fit time: 9.86487078666687 seconds, Predict time: 0.173109769821167 seconds\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model - Initial training\n",
    "model = XGBRegressor(tree_method='hist', random_state=random_state, objective='reg:squarederror')\n",
    "\n",
    "start_fit = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_predict = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "predict_time = time.time() - start_predict\n",
    "\n",
    "rmse = rmse_func(y_test, y_pred)\n",
    "print(f\"XGBoost RMSE: {rmse}\")\n",
    "print(f\"XGBoost Fit time: {fit_time} seconds, Predict time: {predict_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_met[\"rmse_init\"][m_idx[\"xgboost\"]] = rmse\n",
    "log_met[\"fit_time\"][m_idx[\"xgboost\"]] = fit_time\n",
    "log_met[\"predict_time\"][m_idx[\"xgboost\"]] = predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 10, 'objective': 'reg:squarederror'}\n",
      "XGBoost Grid Search Fit time: 410.87535333633423 seconds\n"
     ]
    }
   ],
   "source": [
    "# Grid search for XGBoost\n",
    "param_grid = {\n",
    "    'learning_rate': [0.03, 0.1],\n",
    "    'max_depth': [4, 6, 10],\n",
    "    'objective': ['reg:squarederror']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv=5, n_jobs=1, verbose=False, scoring=rmsle)\n",
    "\n",
    "start_fit = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(f\"XGBoost Grid Search Fit time: {fit_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 318932, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.279718\n",
      "LGBM RMSE: 1852.2844852981566\n",
      "LGBM Fit time: 9.06836748123169 seconds, Predict time: 0.395052433013916 seconds\n"
     ]
    }
   ],
   "source": [
    "# LGBM model\n",
    "model = LGBMRegressor(objective=\"RMSE\", random_state=random_state, verbose=1, force_col_wise=True)\n",
    "\n",
    "start_fit = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_predict = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "predict_time = time.time() - start_predict\n",
    "\n",
    "rmse = rmse_func(y_test, y_pred)\n",
    "print(f\"LGBM RMSE: {rmse}\")\n",
    "print(f\"LGBM Fit time: {fit_time} seconds, Predict time: {predict_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_met[\"rmse_init\"][m_idx[\"LGBM\"]] = rmse\n",
    "log_met[\"fit_time\"][m_idx[\"LGBM\"]] = fit_time\n",
    "log_met[\"predict_time\"][m_idx[\"LGBM\"]] = predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4411.595312\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4418.562084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1425\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.532801\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.395366\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4412.313033\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4411.595312\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4418.562084\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1425\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.532801\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.395366\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4412.313033\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4411.595312\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4418.562084\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1425\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.532801\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.395366\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4412.313033\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4411.595312\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4418.562084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1425\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.532801\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.395366\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4412.313033\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4411.595312\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4418.562084\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1425\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.532801\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.395366\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4412.313033\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4411.595312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255145, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4418.562084\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1425\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.532801\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.395366\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 255146, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4412.313033\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 318932, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 4414.279718\n",
      "{'learning_rate': 0.1, 'max_depth': 10}\n",
      "LGBM Grid Search Fit time: 246.92123293876648 seconds\n"
     ]
    }
   ],
   "source": [
    "# Grid search for LGBM\n",
    "param_grid = {\n",
    "    'learning_rate': [0.03, 0.1],\n",
    "    'max_depth': [4, 6, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv=5, n_jobs=1, verbose=False)\n",
    "\n",
    "start_fit = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(f\"LGBM Grid Search Fit time: {fit_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "LGBM (tuned) RMSE: 1854.528975904095\n",
      "LGBM (tuned) Fit time: 8.787270069122314 seconds, Predict time: 0.3143935203552246 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train final LGBM model with best parameters\n",
    "model = LGBMRegressor(objective=\"RMSE\", random_state=random_state, verbose=0, **grid.best_params_,force_col_wise=True)\n",
    "\n",
    "start_fit = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_predict = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "predict_time = time.time() - start_predict\n",
    "\n",
    "rmse = rmse_func(y_test, y_pred)\n",
    "print(f\"LGBM (tuned) RMSE: {rmse}\")\n",
    "print(f\"LGBM (tuned) Fit time: {fit_time} seconds, Predict time: {predict_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_met[\"rmse_init\"][m_idx[\"LGBM\"]] = rmse\n",
    "log_met[\"fit_time\"][m_idx[\"LGBM\"]] = fit_time\n",
    "log_met[\"predict_time\"][m_idx[\"LGBM\"]] = predict_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>rmse_init</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>predict_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost</td>\n",
       "      <td>2015.126624</td>\n",
       "      <td>2.477708</td>\n",
       "      <td>0.005808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>1771.195954</td>\n",
       "      <td>9.864871</td>\n",
       "      <td>0.173110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>1854.528976</td>\n",
       "      <td>8.787270</td>\n",
       "      <td>0.314394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     models    rmse_init  fit_time  predict_time\n",
       "0  catboost  2015.126624  2.477708      0.005808\n",
       "1   xgboost  1771.195954  9.864871      0.173110\n",
       "2      LGBM  1854.528976  8.787270      0.314394"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(log_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, XGBoost provided the best predictive performance, while CatBoost offered a quick training process and fast predictions, making it suitable for applications where speed is critical. LightGBM presented a balanced option between the two, with reasonable accuracy and training speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [ ]  Code is error free\n",
    "- [ ]  The cells with the code have been arranged in order of execution\n",
    "- [ ]  The data has been downloaded and prepared\n",
    "- [ ]  The models have been trained\n",
    "- [ ]  The analysis of speed and quality of the models has been performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 324,
    "start_time": "2024-07-18T20:52:51.872Z"
   },
   {
    "duration": 5618,
    "start_time": "2024-07-18T20:52:59.455Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-18T20:53:43.149Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-18T21:28:34.848Z"
   },
   {
    "duration": 825,
    "start_time": "2024-07-18T21:29:49.918Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-18T21:30:33.249Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-18T21:30:40.889Z"
   },
   {
    "duration": 159,
    "start_time": "2024-07-18T21:30:58.948Z"
   },
   {
    "duration": 79752,
    "start_time": "2024-07-18T21:32:01.327Z"
   },
   {
    "duration": 54,
    "start_time": "2024-07-18T21:35:02.643Z"
   },
   {
    "duration": 62,
    "start_time": "2024-07-18T21:35:51.719Z"
   },
   {
    "duration": 131,
    "start_time": "2024-07-18T21:36:02.117Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-18T22:02:51.042Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-18T22:03:50.424Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-18T22:04:23.952Z"
   },
   {
    "duration": 33120,
    "start_time": "2024-07-18T22:06:54.298Z"
   },
   {
    "duration": 109,
    "start_time": "2024-07-18T22:07:29.070Z"
   },
   {
    "duration": 29,
    "start_time": "2024-07-18T22:08:01.883Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-18T22:10:26.752Z"
   },
   {
    "duration": 342,
    "start_time": "2024-07-18T22:10:32.957Z"
   },
   {
    "duration": 5264,
    "start_time": "2024-07-23T20:16:12.757Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-23T20:16:20.158Z"
   },
   {
    "duration": 789,
    "start_time": "2024-07-23T20:16:26.041Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:16:27.474Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-23T20:16:28.458Z"
   },
   {
    "duration": 146,
    "start_time": "2024-07-23T20:16:29.451Z"
   },
   {
    "duration": 66,
    "start_time": "2024-07-23T20:17:50.065Z"
   },
   {
    "duration": 61,
    "start_time": "2024-07-23T20:17:50.135Z"
   },
   {
    "duration": 41303,
    "start_time": "2024-07-23T20:17:50.200Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-23T20:18:48.601Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-23T20:18:54.662Z"
   },
   {
    "duration": 757,
    "start_time": "2024-07-23T20:19:00.559Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:19:02.090Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-23T20:19:02.866Z"
   },
   {
    "duration": 161,
    "start_time": "2024-07-23T20:19:04.031Z"
   },
   {
    "duration": 40751,
    "start_time": "2024-07-23T20:20:25.552Z"
   },
   {
    "duration": 73,
    "start_time": "2024-07-23T20:21:06.306Z"
   },
   {
    "duration": 62,
    "start_time": "2024-07-23T20:21:06.383Z"
   },
   {
    "duration": 152,
    "start_time": "2024-07-23T20:21:06.448Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-23T20:21:06.603Z"
   },
   {
    "duration": 34776,
    "start_time": "2024-07-23T20:21:06.616Z"
   },
   {
    "duration": 116,
    "start_time": "2024-07-23T20:21:41.395Z"
   },
   {
    "duration": 771,
    "start_time": "2024-07-23T20:21:41.514Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-23T20:24:43.474Z"
   },
   {
    "duration": 322,
    "start_time": "2024-07-23T20:24:52.139Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-23T20:25:46.176Z"
   },
   {
    "duration": 668,
    "start_time": "2024-07-23T20:25:46.603Z"
   },
   {
    "duration": 3776,
    "start_time": "2024-07-23T20:25:50.954Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-23T20:36:31.344Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-23T20:38:27.924Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-23T20:38:36.663Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:38:50.660Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:41:04.396Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:42:57.735Z"
   },
   {
    "duration": 751,
    "start_time": "2024-07-23T20:46:35.123Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-23T20:47:02.146Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-23T20:47:02.739Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:47:03.257Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:47:04.247Z"
   },
   {
    "duration": 138,
    "start_time": "2024-07-23T20:47:05.408Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-23T20:47:24.741Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-23T20:47:25.155Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-23T20:47:25.559Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-23T20:47:26.027Z"
   },
   {
    "duration": 113,
    "start_time": "2024-07-23T20:47:26.765Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-23T20:49:54.709Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:49:55.451Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:49:55.950Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-23T20:49:56.389Z"
   },
   {
    "duration": 428,
    "start_time": "2024-07-23T20:49:57.357Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-23T20:50:44.908Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:50:45.271Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T20:50:45.541Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-23T20:50:45.840Z"
   },
   {
    "duration": 1243,
    "start_time": "2024-07-23T20:50:46.870Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-24T00:44:32.725Z"
   },
   {
    "duration": 308,
    "start_time": "2024-07-24T00:44:33.128Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T00:44:34.006Z"
   },
   {
    "duration": 5422,
    "start_time": "2024-07-24T00:44:43.702Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T00:44:49.129Z"
   },
   {
    "duration": 817,
    "start_time": "2024-07-24T00:44:49.160Z"
   },
   {
    "duration": 3,
    "start_time": "2024-07-24T00:44:51.336Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-24T00:44:51.865Z"
   },
   {
    "duration": 144,
    "start_time": "2024-07-24T00:44:52.515Z"
   },
   {
    "duration": 79226,
    "start_time": "2024-07-24T00:44:53.301Z"
   },
   {
    "duration": 53,
    "start_time": "2024-07-24T00:46:31.162Z"
   },
   {
    "duration": 55,
    "start_time": "2024-07-24T00:46:32.180Z"
   },
   {
    "duration": 112,
    "start_time": "2024-07-24T00:46:32.831Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-24T00:46:33.548Z"
   },
   {
    "duration": 33140,
    "start_time": "2024-07-24T00:46:34.062Z"
   },
   {
    "duration": 115,
    "start_time": "2024-07-24T00:47:07.205Z"
   },
   {
    "duration": 4798,
    "start_time": "2024-07-24T00:47:10.028Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-24T00:47:38.414Z"
   },
   {
    "duration": 3,
    "start_time": "2024-07-24T00:47:39.575Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T00:47:40.228Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T00:47:41.008Z"
   },
   {
    "duration": 7177,
    "start_time": "2024-07-24T00:47:42.918Z"
   },
   {
    "duration": 1117,
    "start_time": "2024-07-24T00:48:07.380Z"
   },
   {
    "duration": 7081,
    "start_time": "2024-07-24T00:53:51.103Z"
   },
   {
    "duration": 3,
    "start_time": "2024-07-24T00:54:40.761Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T00:54:41.154Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T00:54:41.385Z"
   },
   {
    "duration": 7337,
    "start_time": "2024-07-24T00:54:41.958Z"
   },
   {
    "duration": 7130,
    "start_time": "2024-07-24T00:54:49.298Z"
   },
   {
    "duration": 7002,
    "start_time": "2024-07-24T00:55:27.406Z"
   },
   {
    "duration": 451,
    "start_time": "2024-07-24T00:56:13.133Z"
   },
   {
    "duration": 7104,
    "start_time": "2024-07-24T00:58:28.134Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T01:01:37.364Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T01:01:50.665Z"
   },
   {
    "duration": 645,
    "start_time": "2024-07-24T01:02:11.960Z"
   },
   {
    "duration": 198483,
    "start_time": "2024-07-24T01:09:40.731Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T01:12:59.218Z"
   },
   {
    "duration": 5651,
    "start_time": "2024-07-24T02:32:16.892Z"
   },
   {
    "duration": 27,
    "start_time": "2024-07-24T02:32:22.548Z"
   },
   {
    "duration": 829,
    "start_time": "2024-07-24T02:32:22.578Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T02:32:26.753Z"
   },
   {
    "duration": 28,
    "start_time": "2024-07-24T02:32:27.294Z"
   },
   {
    "duration": 151,
    "start_time": "2024-07-24T02:32:27.912Z"
   },
   {
    "duration": 82592,
    "start_time": "2024-07-24T02:32:28.385Z"
   },
   {
    "duration": 77,
    "start_time": "2024-07-24T02:33:50.980Z"
   },
   {
    "duration": 58,
    "start_time": "2024-07-24T02:35:08.946Z"
   },
   {
    "duration": 159,
    "start_time": "2024-07-24T02:35:09.462Z"
   },
   {
    "duration": 11,
    "start_time": "2024-07-24T02:35:10.055Z"
   },
   {
    "duration": 33665,
    "start_time": "2024-07-24T02:35:11.603Z"
   },
   {
    "duration": 112,
    "start_time": "2024-07-24T02:35:47.203Z"
   },
   {
    "duration": 4861,
    "start_time": "2024-07-24T02:35:47.743Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-24T02:35:55.796Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T02:35:56.681Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T02:35:57.425Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T02:35:58.038Z"
   },
   {
    "duration": 7447,
    "start_time": "2024-07-24T02:35:59.104Z"
   },
   {
    "duration": 7243,
    "start_time": "2024-07-24T02:36:06.556Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T02:36:15.593Z"
   },
   {
    "duration": 199665,
    "start_time": "2024-07-24T02:36:16.740Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T02:39:36.408Z"
   },
   {
    "duration": 1873,
    "start_time": "2024-07-24T02:39:59.570Z"
   },
   {
    "duration": 5323,
    "start_time": "2024-07-24T22:26:13.658Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T22:26:18.990Z"
   },
   {
    "duration": 787,
    "start_time": "2024-07-24T22:26:19.018Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T22:26:22.429Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T22:26:23.433Z"
   },
   {
    "duration": 223,
    "start_time": "2024-07-24T22:26:24.422Z"
   },
   {
    "duration": 79984,
    "start_time": "2024-07-24T22:26:25.256Z"
   },
   {
    "duration": 52,
    "start_time": "2024-07-24T22:27:51.489Z"
   },
   {
    "duration": 56,
    "start_time": "2024-07-24T22:27:52.114Z"
   },
   {
    "duration": 126,
    "start_time": "2024-07-24T22:27:52.664Z"
   },
   {
    "duration": 13,
    "start_time": "2024-07-24T22:27:53.203Z"
   },
   {
    "duration": 33323,
    "start_time": "2024-07-24T22:27:53.720Z"
   },
   {
    "duration": 118,
    "start_time": "2024-07-24T22:28:27.046Z"
   },
   {
    "duration": 4825,
    "start_time": "2024-07-24T22:28:27.167Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-24T22:28:31.996Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T22:28:32.010Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T22:28:46.730Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T22:28:47.404Z"
   },
   {
    "duration": 7232,
    "start_time": "2024-07-24T22:28:48.347Z"
   },
   {
    "duration": 7054,
    "start_time": "2024-07-24T22:28:55.582Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T22:29:28.907Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-24T22:32:51.839Z"
   },
   {
    "duration": 198861,
    "start_time": "2024-07-24T22:32:51.862Z"
   },
   {
    "duration": 13935,
    "start_time": "2024-07-24T22:36:10.727Z"
   },
   {
    "duration": 426,
    "start_time": "2024-07-24T22:37:13.669Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-24T22:37:34.058Z"
   },
   {
    "duration": 1416,
    "start_time": "2024-07-24T22:38:14.001Z"
   },
   {
    "duration": 2132,
    "start_time": "2024-07-24T22:38:42.486Z"
   },
   {
    "duration": 13585,
    "start_time": "2024-07-24T22:44:07.137Z"
   },
   {
    "duration": 155,
    "start_time": "2024-07-24T22:45:04.356Z"
   },
   {
    "duration": 131,
    "start_time": "2024-07-24T22:45:08.764Z"
   },
   {
    "duration": 18467,
    "start_time": "2024-07-24T22:45:48.299Z"
   },
   {
    "duration": 379,
    "start_time": "2024-07-24T22:48:00.834Z"
   },
   {
    "duration": 1776,
    "start_time": "2024-07-24T22:48:45.762Z"
   },
   {
    "duration": 149,
    "start_time": "2024-07-24T22:48:52.777Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-24T22:48:58.231Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T22:48:58.814Z"
   },
   {
    "duration": 795,
    "start_time": "2024-07-24T22:49:00.588Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T22:49:01.992Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T22:49:02.582Z"
   },
   {
    "duration": 153,
    "start_time": "2024-07-24T22:49:02.985Z"
   },
   {
    "duration": 80195,
    "start_time": "2024-07-24T22:49:03.306Z"
   },
   {
    "duration": 64,
    "start_time": "2024-07-24T22:50:23.505Z"
   },
   {
    "duration": 74,
    "start_time": "2024-07-24T22:50:23.572Z"
   },
   {
    "duration": 111,
    "start_time": "2024-07-24T22:50:35.907Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-24T22:50:36.633Z"
   },
   {
    "duration": 34016,
    "start_time": "2024-07-24T22:50:37.268Z"
   },
   {
    "duration": 109,
    "start_time": "2024-07-24T22:51:19.263Z"
   },
   {
    "duration": 4891,
    "start_time": "2024-07-24T22:51:19.892Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-24T22:51:27.506Z"
   },
   {
    "duration": 3,
    "start_time": "2024-07-24T22:51:31.361Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T22:51:32.138Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T22:51:32.648Z"
   },
   {
    "duration": 7155,
    "start_time": "2024-07-24T22:51:33.686Z"
   },
   {
    "duration": 7123,
    "start_time": "2024-07-24T22:51:42.897Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T22:51:51.196Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T22:55:11.670Z"
   },
   {
    "duration": 200029,
    "start_time": "2024-07-24T22:55:11.692Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-24T22:58:31.726Z"
   },
   {
    "duration": 13913,
    "start_time": "2024-07-24T22:58:42.783Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T22:59:06.567Z"
   },
   {
    "duration": 13542,
    "start_time": "2024-07-24T22:59:07.877Z"
   },
   {
    "duration": 131,
    "start_time": "2024-07-24T22:59:22.567Z"
   },
   {
    "duration": 339,
    "start_time": "2024-07-24T23:05:26.570Z"
   },
   {
    "duration": 1710,
    "start_time": "2024-07-24T23:06:16.434Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T23:06:18.147Z"
   },
   {
    "duration": 782,
    "start_time": "2024-07-24T23:06:18.176Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T23:06:18.962Z"
   },
   {
    "duration": 35,
    "start_time": "2024-07-24T23:06:18.969Z"
   },
   {
    "duration": 168,
    "start_time": "2024-07-24T23:06:19.007Z"
   },
   {
    "duration": 78707,
    "start_time": "2024-07-24T23:06:19.178Z"
   },
   {
    "duration": 56,
    "start_time": "2024-07-24T23:07:37.892Z"
   },
   {
    "duration": 72,
    "start_time": "2024-07-24T23:07:37.951Z"
   },
   {
    "duration": 123,
    "start_time": "2024-07-24T23:07:38.031Z"
   },
   {
    "duration": 11,
    "start_time": "2024-07-24T23:07:38.158Z"
   },
   {
    "duration": 34973,
    "start_time": "2024-07-24T23:07:38.191Z"
   },
   {
    "duration": 131,
    "start_time": "2024-07-24T23:08:13.167Z"
   },
   {
    "duration": 4941,
    "start_time": "2024-07-24T23:08:13.301Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-24T23:08:18.245Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T23:08:18.262Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T23:08:18.293Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T23:08:18.302Z"
   },
   {
    "duration": 7718,
    "start_time": "2024-07-24T23:08:18.309Z"
   },
   {
    "duration": 7449,
    "start_time": "2024-07-24T23:08:26.031Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-24T23:08:33.485Z"
   },
   {
    "duration": 200298,
    "start_time": "2024-07-24T23:08:33.497Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-24T23:11:53.798Z"
   },
   {
    "duration": 13854,
    "start_time": "2024-07-24T23:11:53.819Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T23:12:07.676Z"
   },
   {
    "duration": 13313,
    "start_time": "2024-07-24T23:12:07.684Z"
   },
   {
    "duration": 201,
    "start_time": "2024-07-24T23:12:21.000Z"
   },
   {
    "duration": 433384,
    "start_time": "2024-07-24T23:12:21.207Z"
   },
   {
    "duration": 443,
    "start_time": "2024-07-24T23:24:56.609Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T23:25:47.179Z"
   },
   {
    "duration": 24810,
    "start_time": "2024-07-24T23:27:02.712Z"
   },
   {
    "duration": 423,
    "start_time": "2024-07-24T23:29:23.085Z"
   },
   {
    "duration": 391,
    "start_time": "2024-07-24T23:29:29.523Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-24T23:33:44.462Z"
   },
   {
    "duration": 1262,
    "start_time": "2024-07-24T23:34:06.096Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T23:34:24.689Z"
   },
   {
    "duration": 9854,
    "start_time": "2024-07-24T23:34:29.043Z"
   },
   {
    "duration": 353,
    "start_time": "2024-07-24T23:34:52.544Z"
   },
   {
    "duration": 404,
    "start_time": "2024-07-24T23:34:56.086Z"
   },
   {
    "duration": 321,
    "start_time": "2024-07-24T23:36:26.038Z"
   },
   {
    "duration": 1690,
    "start_time": "2024-07-24T23:36:39.633Z"
   },
   {
    "duration": 27,
    "start_time": "2024-07-24T23:36:41.327Z"
   },
   {
    "duration": 796,
    "start_time": "2024-07-24T23:36:41.357Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-24T23:36:42.158Z"
   },
   {
    "duration": 36,
    "start_time": "2024-07-24T23:36:42.168Z"
   },
   {
    "duration": 152,
    "start_time": "2024-07-24T23:36:42.207Z"
   },
   {
    "duration": 78664,
    "start_time": "2024-07-24T23:36:42.362Z"
   },
   {
    "duration": 65,
    "start_time": "2024-07-24T23:38:01.029Z"
   },
   {
    "duration": 55,
    "start_time": "2024-07-24T23:38:01.097Z"
   },
   {
    "duration": 138,
    "start_time": "2024-07-24T23:38:01.159Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-24T23:38:01.300Z"
   },
   {
    "duration": 33586,
    "start_time": "2024-07-24T23:38:01.313Z"
   },
   {
    "duration": 120,
    "start_time": "2024-07-24T23:38:34.902Z"
   },
   {
    "duration": 4880,
    "start_time": "2024-07-24T23:38:35.025Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-24T23:38:39.908Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T23:38:39.923Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T23:38:39.931Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T23:38:39.940Z"
   },
   {
    "duration": 7277,
    "start_time": "2024-07-24T23:38:39.992Z"
   },
   {
    "duration": 7151,
    "start_time": "2024-07-24T23:38:47.271Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T23:38:54.425Z"
   },
   {
    "duration": 198570,
    "start_time": "2024-07-24T23:38:54.434Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T23:42:13.007Z"
   },
   {
    "duration": 13639,
    "start_time": "2024-07-24T23:42:13.030Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-24T23:42:26.673Z"
   },
   {
    "duration": 14426,
    "start_time": "2024-07-24T23:42:26.684Z"
   },
   {
    "duration": 192,
    "start_time": "2024-07-24T23:42:41.114Z"
   },
   {
    "duration": 5760,
    "start_time": "2024-07-25T18:02:33.380Z"
   },
   {
    "duration": 27,
    "start_time": "2024-07-25T18:02:43.227Z"
   },
   {
    "duration": 931,
    "start_time": "2024-07-25T18:02:44.244Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-25T18:02:45.178Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-25T18:02:46.011Z"
   },
   {
    "duration": 152,
    "start_time": "2024-07-25T18:02:47.157Z"
   },
   {
    "duration": 80143,
    "start_time": "2024-07-25T18:02:48.076Z"
   },
   {
    "duration": 55,
    "start_time": "2024-07-25T18:04:10.014Z"
   },
   {
    "duration": 66,
    "start_time": "2024-07-25T18:04:10.644Z"
   },
   {
    "duration": 120,
    "start_time": "2024-07-25T18:04:11.325Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-25T18:04:12.182Z"
   },
   {
    "duration": 37939,
    "start_time": "2024-07-25T18:04:12.995Z"
   },
   {
    "duration": 115,
    "start_time": "2024-07-25T18:04:50.938Z"
   },
   {
    "duration": 5896,
    "start_time": "2024-07-25T18:05:42.916Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-25T18:05:51.487Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-25T18:05:54.227Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-25T18:05:54.997Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-25T18:05:55.467Z"
   },
   {
    "duration": 7458,
    "start_time": "2024-07-25T18:05:56.815Z"
   },
   {
    "duration": 7484,
    "start_time": "2024-07-25T18:06:12.162Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-25T18:06:20.957Z"
   },
   {
    "duration": 200537,
    "start_time": "2024-07-25T18:06:25.266Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-25T18:09:45.807Z"
   },
   {
    "duration": 13974,
    "start_time": "2024-07-25T18:10:02.215Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-25T18:10:22.225Z"
   },
   {
    "duration": 30430,
    "start_time": "2024-07-25T18:10:23.167Z"
   },
   {
    "duration": 161,
    "start_time": "2024-07-25T18:10:56.009Z"
   },
   {
    "duration": 441624,
    "start_time": "2024-07-25T18:18:42.585Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-25T18:27:33.224Z"
   },
   {
    "duration": 25036,
    "start_time": "2024-07-25T18:27:39.173Z"
   },
   {
    "duration": 342,
    "start_time": "2024-07-25T18:28:10.958Z"
   },
   {
    "duration": 1235,
    "start_time": "2024-07-25T18:28:20.769Z"
   },
   {
    "duration": 1279,
    "start_time": "2024-07-25T18:28:28.610Z"
   },
   {
    "duration": 10000,
    "start_time": "2024-07-25T18:28:43.090Z"
   },
   {
    "duration": 323,
    "start_time": "2024-07-25T18:29:06.176Z"
   },
   {
    "duration": 268921,
    "start_time": "2024-07-25T18:29:16.178Z"
   },
   {
    "duration": 9753,
    "start_time": "2024-07-25T18:34:53.186Z"
   },
   {
    "duration": 12278,
    "start_time": "2024-07-25T18:36:21.093Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-25T18:37:12.829Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-25T18:37:17.487Z"
   },
   {
    "duration": 5209,
    "start_time": "2024-07-26T08:35:44.458Z"
   },
   {
    "duration": 37,
    "start_time": "2024-07-26T08:35:49.671Z"
   },
   {
    "duration": 784,
    "start_time": "2024-07-26T08:35:49.711Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-26T08:35:50.499Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-26T08:35:51.778Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-26T08:37:47.215Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-26T08:37:53.407Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-26T08:57:34.691Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-26T08:57:34.773Z"
   },
   {
    "duration": 730,
    "start_time": "2024-07-26T08:57:34.860Z"
   },
   {
    "duration": 3,
    "start_time": "2024-07-26T08:57:35.594Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-26T08:57:35.607Z"
   },
   {
    "duration": 161,
    "start_time": "2024-07-26T08:57:35.633Z"
   },
   {
    "duration": 79113,
    "start_time": "2024-07-26T08:57:35.806Z"
   },
   {
    "duration": 52,
    "start_time": "2024-07-26T08:58:54.922Z"
   },
   {
    "duration": 73,
    "start_time": "2024-07-26T08:58:54.977Z"
   },
   {
    "duration": 121,
    "start_time": "2024-07-26T08:58:55.053Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-26T08:58:55.177Z"
   },
   {
    "duration": 32114,
    "start_time": "2024-07-26T08:58:55.209Z"
   },
   {
    "duration": 117,
    "start_time": "2024-07-26T08:59:27.326Z"
   },
   {
    "duration": 4787,
    "start_time": "2024-07-26T08:59:27.446Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-26T08:59:32.236Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-26T08:59:32.248Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-26T08:59:32.258Z"
   },
   {
    "duration": 40,
    "start_time": "2024-07-26T08:59:32.266Z"
   },
   {
    "duration": 7489,
    "start_time": "2024-07-26T08:59:32.308Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-26T09:00:06.113Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-26T09:00:26.942Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-26T09:00:35.155Z"
   },
   {
    "duration": 5588,
    "start_time": "2024-07-29T18:55:12.853Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-29T18:55:20.937Z"
   },
   {
    "duration": 812,
    "start_time": "2024-07-29T18:55:21.701Z"
   },
   {
    "duration": 3,
    "start_time": "2024-07-29T18:55:24.987Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-29T18:55:26.773Z"
   },
   {
    "duration": 169,
    "start_time": "2024-07-29T18:55:28.683Z"
   },
   {
    "duration": 82120,
    "start_time": "2024-07-29T18:55:30.110Z"
   },
   {
    "duration": 55,
    "start_time": "2024-07-29T18:58:02.999Z"
   },
   {
    "duration": 60,
    "start_time": "2024-07-29T18:58:03.957Z"
   },
   {
    "duration": 113,
    "start_time": "2024-07-29T18:58:05.075Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-29T18:58:06.960Z"
   },
   {
    "duration": 33414,
    "start_time": "2024-07-29T18:58:08.838Z"
   },
   {
    "duration": 109,
    "start_time": "2024-07-29T18:58:46.927Z"
   },
   {
    "duration": 4929,
    "start_time": "2024-07-29T18:58:47.714Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-29T18:59:12.303Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-29T18:59:13.523Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-29T18:59:14.454Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-29T18:59:18.137Z"
   },
   {
    "duration": 7335,
    "start_time": "2024-07-29T18:59:19.653Z"
   },
   {
    "duration": 195469,
    "start_time": "2024-07-29T19:03:52.534Z"
   },
   {
    "duration": 11,
    "start_time": "2024-07-29T19:30:18.654Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-29T19:30:19.633Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-29T19:30:20.310Z"
   },
   {
    "duration": 4618,
    "start_time": "2024-07-29T19:30:21.733Z"
   },
   {
    "duration": 427,
    "start_time": "2024-07-29T19:31:34.311Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-29T19:32:10.481Z"
   },
   {
    "duration": 7200,
    "start_time": "2024-07-29T19:32:17.894Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-29T19:32:35.191Z"
   },
   {
    "duration": 178752,
    "start_time": "2024-07-29T19:38:38.680Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-29T19:41:37.436Z"
   },
   {
    "duration": 13811,
    "start_time": "2024-07-29T19:43:20.795Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-29T19:44:48.700Z"
   },
   {
    "duration": 322,
    "start_time": "2024-08-01T20:11:07.082Z"
   },
   {
    "duration": 30,
    "start_time": "2024-08-01T20:11:19.336Z"
   },
   {
    "duration": 29,
    "start_time": "2024-08-01T20:11:25.101Z"
   },
   {
    "duration": 5353,
    "start_time": "2024-08-01T20:12:46.710Z"
   },
   {
    "duration": 24,
    "start_time": "2024-08-01T20:12:52.067Z"
   },
   {
    "duration": 822,
    "start_time": "2024-08-01T20:12:52.094Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-01T20:12:55.322Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-01T20:12:56.645Z"
   },
   {
    "duration": 147,
    "start_time": "2024-08-01T20:12:57.789Z"
   },
   {
    "duration": 80545,
    "start_time": "2024-08-01T20:12:58.580Z"
   },
   {
    "duration": 61,
    "start_time": "2024-08-01T20:14:54.707Z"
   },
   {
    "duration": 58,
    "start_time": "2024-08-01T20:14:55.395Z"
   },
   {
    "duration": 110,
    "start_time": "2024-08-01T20:14:56.228Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-01T20:14:58.814Z"
   },
   {
    "duration": 32787,
    "start_time": "2024-08-01T20:14:59.565Z"
   },
   {
    "duration": 109,
    "start_time": "2024-08-01T20:15:58.138Z"
   },
   {
    "duration": 4788,
    "start_time": "2024-08-01T20:15:59.193Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-01T20:16:10.288Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:16:13.399Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:16:15.569Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-01T20:16:16.421Z"
   },
   {
    "duration": 7126,
    "start_time": "2024-08-01T20:16:19.330Z"
   },
   {
    "duration": 7103,
    "start_time": "2024-08-01T20:16:40.439Z"
   },
   {
    "duration": 179133,
    "start_time": "2024-08-01T20:16:58.286Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:19:57.423Z"
   },
   {
    "duration": 13807,
    "start_time": "2024-08-01T20:20:26.452Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:21:22.207Z"
   },
   {
    "duration": 860,
    "start_time": "2024-08-01T20:21:23.834Z"
   },
   {
    "duration": 740,
    "start_time": "2024-08-01T20:24:50.341Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-01T20:24:52.695Z"
   },
   {
    "duration": 22,
    "start_time": "2024-08-01T20:25:13.649Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-01T20:25:23.701Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-01T20:25:25.946Z"
   },
   {
    "duration": 157,
    "start_time": "2024-08-01T20:25:30.206Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-01T20:27:29.246Z"
   },
   {
    "duration": 8413,
    "start_time": "2024-08-01T20:27:31.023Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-01T20:27:59.281Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:28:16.176Z"
   },
   {
    "duration": 155,
    "start_time": "2024-08-01T20:28:17.788Z"
   },
   {
    "duration": 32,
    "start_time": "2024-08-01T20:30:12.654Z"
   },
   {
    "duration": 155,
    "start_time": "2024-08-01T20:30:14.685Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-01T20:33:12.617Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:33:13.156Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-01T20:33:13.719Z"
   },
   {
    "duration": 3880,
    "start_time": "2024-08-01T20:33:15.417Z"
   },
   {
    "duration": 10024,
    "start_time": "2024-08-01T20:33:32.813Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:33:48.045Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-01T20:33:50.389Z"
   },
   {
    "duration": 9,
    "start_time": "2024-08-01T20:48:37.107Z"
   },
   {
    "duration": 24,
    "start_time": "2024-08-01T20:48:41.823Z"
   },
   {
    "duration": 8258,
    "start_time": "2024-08-01T20:49:29.750Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:49:40.938Z"
   },
   {
    "duration": 10034,
    "start_time": "2024-08-01T20:49:42.705Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T20:50:02.655Z"
   },
   {
    "duration": 413762,
    "start_time": "2024-08-01T20:50:03.513Z"
   },
   {
    "duration": 9741,
    "start_time": "2024-08-01T20:57:04.891Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-01T20:57:20.407Z"
   },
   {
    "duration": 235166,
    "start_time": "2024-08-01T20:57:22.165Z"
   },
   {
    "duration": 9609,
    "start_time": "2024-08-01T21:01:36.830Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T21:01:49.609Z"
   },
   {
    "duration": 243245,
    "start_time": "2024-08-01T21:01:50.503Z"
   },
   {
    "duration": 9749,
    "start_time": "2024-08-01T21:06:05.284Z"
   },
   {
    "duration": 9411,
    "start_time": "2024-08-01T21:06:30.011Z"
   },
   {
    "duration": 10114,
    "start_time": "2024-08-01T21:08:19.127Z"
   },
   {
    "duration": 9532,
    "start_time": "2024-08-01T21:08:41.780Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T21:09:43.191Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-01T21:09:46.287Z"
   },
   {
    "duration": 2537,
    "start_time": "2024-08-01T21:13:02.902Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T21:13:28.630Z"
   },
   {
    "duration": 95288,
    "start_time": "2024-08-01T21:15:52.287Z"
   },
   {
    "duration": 3,
    "start_time": "2024-08-01T21:17:44.428Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-01T21:17:51.801Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-01T21:23:53.472Z"
   },
   {
    "duration": 3,
    "start_time": "2024-08-01T21:24:01.199Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-01T21:24:22.511Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-01T21:24:26.310Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T21:24:34.882Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-01T21:24:38.124Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-01T21:25:54.500Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-01T21:26:05.265Z"
   },
   {
    "duration": 12,
    "start_time": "2024-08-01T21:26:07.593Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-01T21:29:07.005Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-01T21:29:41.704Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T21:29:44.626Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-01T21:29:46.711Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-01T21:30:33.626Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T21:30:34.619Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-01T21:30:40.365Z"
   },
   {
    "duration": 3762,
    "start_time": "2024-08-01T21:30:41.728Z"
   },
   {
    "duration": 2499,
    "start_time": "2024-08-01T21:30:47.404Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T21:30:52.149Z"
   },
   {
    "duration": 95189,
    "start_time": "2024-08-01T21:30:53.315Z"
   },
   {
    "duration": 8293,
    "start_time": "2024-08-01T21:32:28.509Z"
   },
   {
    "duration": 10160,
    "start_time": "2024-08-01T21:32:42.878Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-01T21:32:55.317Z"
   },
   {
    "duration": 306,
    "start_time": "2024-08-02T06:42:01.385Z"
   },
   {
    "duration": 5413,
    "start_time": "2024-08-02T06:42:13.248Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-02T06:42:18.664Z"
   },
   {
    "duration": 811,
    "start_time": "2024-08-02T06:42:18.695Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T06:42:19.511Z"
   },
   {
    "duration": 23,
    "start_time": "2024-08-02T06:42:19.518Z"
   },
   {
    "duration": 220,
    "start_time": "2024-08-02T06:42:19.567Z"
   },
   {
    "duration": 79212,
    "start_time": "2024-08-02T06:42:19.790Z"
   },
   {
    "duration": 62,
    "start_time": "2024-08-02T06:43:39.005Z"
   },
   {
    "duration": 56,
    "start_time": "2024-08-02T06:43:39.071Z"
   },
   {
    "duration": 134,
    "start_time": "2024-08-02T06:43:39.133Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T06:43:39.270Z"
   },
   {
    "duration": 32618,
    "start_time": "2024-08-02T06:43:39.285Z"
   },
   {
    "duration": 113,
    "start_time": "2024-08-02T06:44:11.906Z"
   },
   {
    "duration": 4728,
    "start_time": "2024-08-02T06:44:12.022Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-02T06:44:16.753Z"
   },
   {
    "duration": 6,
    "start_time": "2024-08-02T06:44:16.779Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-02T06:44:16.789Z"
   },
   {
    "duration": 4982,
    "start_time": "2024-08-02T06:44:16.797Z"
   },
   {
    "duration": 2612,
    "start_time": "2024-08-02T06:44:21.782Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-02T06:44:24.397Z"
   },
   {
    "duration": 95072,
    "start_time": "2024-08-02T06:44:24.405Z"
   },
   {
    "duration": 8292,
    "start_time": "2024-08-02T06:45:59.481Z"
   },
   {
    "duration": 9992,
    "start_time": "2024-08-02T06:46:07.777Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-02T06:46:17.772Z"
   },
   {
    "duration": 417714,
    "start_time": "2024-08-02T06:46:17.780Z"
   },
   {
    "duration": 9389,
    "start_time": "2024-08-02T06:53:15.498Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T06:53:24.890Z"
   },
   {
    "duration": 249070,
    "start_time": "2024-08-02T06:53:24.903Z"
   },
   {
    "duration": 9416,
    "start_time": "2024-08-02T06:57:33.976Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T06:57:43.395Z"
   },
   {
    "duration": 74,
    "start_time": "2024-08-02T06:57:43.402Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T07:01:39.264Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T07:01:45.271Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T07:02:07.927Z"
   },
   {
    "duration": 4839,
    "start_time": "2024-08-02T07:02:09.425Z"
   },
   {
    "duration": 13,
    "start_time": "2024-08-02T07:02:18.398Z"
   },
   {
    "duration": 2544,
    "start_time": "2024-08-02T07:02:27.876Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-02T07:02:34.364Z"
   },
   {
    "duration": 95297,
    "start_time": "2024-08-02T07:03:20.256Z"
   },
   {
    "duration": 8236,
    "start_time": "2024-08-02T07:06:02.682Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T07:06:26.911Z"
   },
   {
    "duration": 4908,
    "start_time": "2024-08-02T07:06:27.821Z"
   },
   {
    "duration": 2490,
    "start_time": "2024-08-02T07:06:42.593Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T07:06:46.185Z"
   },
   {
    "duration": 94978,
    "start_time": "2024-08-02T07:06:50.342Z"
   },
   {
    "duration": 8292,
    "start_time": "2024-08-02T07:08:40.531Z"
   },
   {
    "duration": 10045,
    "start_time": "2024-08-02T07:09:15.832Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T07:09:28.254Z"
   },
   {
    "duration": 410883,
    "start_time": "2024-08-02T07:09:30.294Z"
   },
   {
    "duration": 9470,
    "start_time": "2024-08-02T07:16:24.514Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T07:16:40.963Z"
   },
   {
    "duration": 246928,
    "start_time": "2024-08-02T07:16:44.044Z"
   },
   {
    "duration": 9109,
    "start_time": "2024-08-02T07:20:57.585Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T07:21:11.669Z"
   },
   {
    "duration": 11,
    "start_time": "2024-08-02T07:21:14.291Z"
   },
   {
    "duration": 1662,
    "start_time": "2024-08-02T08:46:31.395Z"
   },
   {
    "duration": 26,
    "start_time": "2024-08-02T08:46:33.060Z"
   },
   {
    "duration": 804,
    "start_time": "2024-08-02T08:46:33.089Z"
   },
   {
    "duration": 4,
    "start_time": "2024-08-02T08:46:33.897Z"
   },
   {
    "duration": 38,
    "start_time": "2024-08-02T08:46:33.904Z"
   },
   {
    "duration": 154,
    "start_time": "2024-08-02T08:46:33.945Z"
   },
   {
    "duration": 78309,
    "start_time": "2024-08-02T08:46:34.102Z"
   },
   {
    "duration": 57,
    "start_time": "2024-08-02T08:47:52.413Z"
   },
   {
    "duration": 74,
    "start_time": "2024-08-02T08:47:52.472Z"
   },
   {
    "duration": 117,
    "start_time": "2024-08-02T08:47:52.552Z"
   },
   {
    "duration": 10,
    "start_time": "2024-08-02T08:47:52.672Z"
   },
   {
    "duration": 14,
    "start_time": "2024-08-02T08:48:53.713Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-02T08:49:48.304Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
